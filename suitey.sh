#!/bin/bash

set -euo pipefail

# ============================================================================
# Suitey - Project Scanner and Test Framework Detector
# ============================================================================
# Description: Suitey is a project scanner that detects test frameworks (BATS, Rust)
# and discovers test suites within project directories. It provides structured
# output about detected frameworks and their test suites for automated testing
# workflows.
# Purpose: Enables automated detection and execution of tests across multiple
# testing frameworks without manual configuration or framework-specific logic.
# Usage: suitey.sh [OPTIONS] [PROJECT_ROOT]
# This file is auto-generated by build.sh - do not edit manually
#
# Editor hints: Use single-tab indentation (tabstop=4, noexpandtab)
# vim: set tabstop=4 shiftwidth=4 noexpandtab:
# Local Variables:
# tab-width: 4
# indent-tabs-mode: t
# End:
# ============================================================================

# ============================================================================
# Source: src/common.sh
# ============================================================================
# ============================================================================
# Common Helper Functions and State
# ============================================================================
#

# Colors for output (if terminal supports it)
if [[ -t 1 ]]; then
	RED='\033[0;31m'
	GREEN='\033[0;32m'
	YELLOW='\033[1;33m'
	BLUE='\033[0;34m'
	NC='\033[0m' # No Color
else
	RED=''
	GREEN=''
	YELLOW=''
	BLUE=''
	NC=''
fi

# Scanner state
DETECTED_FRAMEWORKS=()
DISCOVERED_SUITES=()
SCAN_ERRORS=()

# ============================================================================
# Common Helper Functions
# ============================================================================

# Check if a command binary is available
check_binary() {
	local cmd="$1"
	command -v "$cmd" >/dev/null 2>&1
}

# Normalize a file path to absolute path
normalize_path() {
	local file="$1"
	if command -v readlink >/dev/null 2>&1; then
	readlink -f "$file" 2>/dev/null || realpath "$file" 2>/dev/null || echo "$file"
	elif command -v realpath >/dev/null 2>&1; then
	realpath "$file" 2>/dev/null || echo "$file"
	else
	echo "$file"
	fi
}

# Check if a file is already in the seen_files array
is_file_seen() {
	local file="$1"
	shift
	local seen_files=("$@")
	local normalized_file
	normalized_file=$(normalize_path "$file")

	for seen in "${seen_files[@]}"; do
	if [[ "$seen" == "$normalized_file" ]]; then
	return 0
	fi
	done
	return 1
}

# Generate suite name from file path
generate_suite_name() {
	local file="$1"
	local extension="$2"
	local rel_path="${file#$PROJECT_ROOT/}"
	rel_path="${rel_path#/}"

	local suite_name="${rel_path%.${extension}}"
	suite_name="${suite_name//\//-}"

	if [[ -z "$suite_name" ]]; then
	suite_name=$(basename "$file" ".${extension}")
	fi

	echo "$suite_name"
}

# Get absolute path for a file
get_absolute_path() {
	local file="$1"
	if [[ "$file" != /* ]]; then
	echo "$(cd "$(dirname "$file")" && pwd)/$(basename "$file")"
	else
	echo "$file"
	fi
}

# Count test annotations in a file
count_tests_in_file() {
	local file="$1"
	local pattern="$2"
	local count=0

	if [[ ! -f "$file" ]] || [[ ! -r "$file" ]]; then
	echo "0"
	return
	fi

	while IFS= read -r line || [[ -n "$line" ]]; do
	trimmed_line="${line#"${line%%[![:space:]]*}"}"
	if [[ "$trimmed_line" == "$pattern"* ]]; then
	((count++))
	fi
	done < "$file"

	echo "$count"
}


# ============================================================================
# Source: src/json_helpers.sh
# ============================================================================
# ============================================================================
# JSON Helper Functions
# ============================================================================
# Standardized JSON operations using jq, with consistent error handling
# and performance optimizations for repeated use.
#

# ============================================================================
# Core JSON Access Functions
# ============================================================================

# Extract a value from JSON using a jq path
# Arguments:
#   json: JSON string
#   path: jq path expression (e.g., '.field', '.array[0]')
# Returns:
#   Extracted value as string, or empty string on error
json_get() {
	local json="$1"
	local path="$2"

	# Validate inputs
	if [[ -z "$json" ]] || [[ -z "$path" ]]; then
	return 1
	fi

	# Strip REGISTRY_END and other markers that might pollute JSON output
	json="${json%%REGISTRY_END*}"
	json="${json%%CAPABILITIES_END*}"
	json="${json%%ORDER_END*}"
	json="${json#*REGISTRY_START}"
	json="${json#*CAPABILITIES_START}"
	json="${json#*ORDER_START}"

	echo "$json" | jq -r "$path" 2>/dev/null || return 1
}

# Extract an array from JSON as a newline-separated string
# Arguments:
#   json: JSON string
#   path: jq path to array (e.g., '.items', '.array')
# Returns:
#   Array elements one per line, or empty on error
json_get_array() {
	local json="$1"
	local path="$2"

	if [[ -z "$json" ]] || [[ -z "$path" ]]; then
	return 1
	fi

	# Strip REGISTRY_END and other markers that might pollute JSON output
	json="${json%%REGISTRY_END*}"
	json="${json%%CAPABILITIES_END*}"
	json="${json%%ORDER_END*}"
	json="${json#*REGISTRY_START}"
	json="${json#*CAPABILITIES_START}"
	json="${json#*ORDER_START}"

	echo "$json" | jq -r "$path[]?" 2>/dev/null || return 1
}

# Get the length of a JSON array
# Arguments:
#   json: JSON string
# Returns:
#   Array length as integer, or 0 on error
json_array_length() {
	local json="$1"

	if [[ -z "$json" ]]; then
	echo "0"
	return 1
	fi

	echo "$json" | jq 'length' 2>/dev/null || echo "0"
}

# Get an element from a JSON array by index
# Arguments:
#   json: JSON string
#   index: Array index (0-based)
# Returns:
#   Array element as string, or empty on error
json_array_get() {
	local json="$1"
	local index="$2"

	if [[ -z "$json" ]] || ! [[ "$index" =~ ^[0-9]+$ ]]; then
	return 1
	fi

	echo "$json" | jq -r ".[$index]" 2>/dev/null || return 1
}

# Check if a JSON object has a specific field
# Arguments:
#   json: JSON string
#   field: Field name to check
# Returns:
#   0 if field exists, 1 if not
json_has_field() {
	local json="$1"
	local field="$2"

	if [[ -z "$json" ]] || [[ -z "$field" ]]; then
	return 1
	fi

	# Strip REGISTRY_END and other markers that might pollute JSON output
	json="${json%%REGISTRY_END*}"
	json="${json%%CAPABILITIES_END*}"
	json="${json%%ORDER_END*}"
	json="${json#*REGISTRY_START}"
	json="${json#*CAPABILITIES_START}"
	json="${json#*ORDER_START}"

	echo "$json" | jq -e "has(\"$field\")" >/dev/null 2>&1
}

# ============================================================================
# JSON Modification Functions
# ============================================================================

# Set a value in JSON (creates new JSON with updated value)
# Arguments:
#   json: Original JSON string
#   path: jq path to set
#   value: New value (will be JSON-encoded)
# Returns:
#   Updated JSON string, or original on error
json_set() {
	local json="$1"
	local path="$2"
	local value="$3"

	if [[ -z "$json" ]] || [[ -z "$path" ]]; then
	echo "$json"
	return 1
	fi

	echo "$json" | jq "$path = $value" 2>/dev/null || echo "$json"
}

# Append a value to a JSON array
# Arguments:
#   json: JSON array string
#   value: Value to append (will be JSON-encoded)
# Returns:
#   Updated JSON array, or original on error
json_array_append() {
	local json="$1"
	local value="$2"

	if [[ -z "$json" ]]; then
	echo "[$value]"
	return
	fi

	echo "$json" | jq ". += [$value]" 2>/dev/null || echo "$json"
}

# Merge two JSON objects or arrays
# Arguments:
#   json1: First JSON string
#   json2: Second JSON string
# Returns:
#   Merged JSON, or json1 on error
json_merge() {
	local json1="$1"
	local json2="$2"

	if [[ -z "$json1" ]]; then
	echo "$json2"
	return
	fi

	if [[ -z "$json2" ]]; then
	echo "$json1"
	return
	fi

	echo "$json1 $json2" | jq -s '.[0] + .[1]' 2>/dev/null || echo "$json1"
}

# ============================================================================
# JSON Validation Functions
# ============================================================================

# Validate that a string is valid JSON
# Arguments:
#   json: String to validate
# Returns:
#   0 if valid JSON, 1 if invalid
json_validate() {
	local json="$1"

	if [[ -z "$json" ]]; then
	return 1
	fi

	echo "$json" | jq . >/dev/null 2>&1
}

# Check if JSON represents an array
# Arguments:
#   json: JSON string
# Returns:
#   0 if array, 1 if not
json_is_array() {
	local json="$1"

	if [[ -z "$json" ]]; then
	return 1
	fi

	echo "$json" | jq -e 'type == "array"' >/dev/null 2>&1
}

# Check if JSON represents an object
# Arguments:
#   json: JSON string
# Returns:
#   0 if object, 1 if not
json_is_object() {
	local json="$1"

	if [[ -z "$json" ]]; then
	return 1
	fi

	echo "$json" | jq -e 'type == "object"' >/dev/null 2>&1
}

# ============================================================================
# Array â†” JSON Conversion Functions
# ============================================================================

# Convert a JSON array to a Bash array
# Arguments:
#   json: JSON array string
# Returns:
#   Returns: first line = count, subsequent lines = array elements (one per line)
#
# PATTERN: Return-Data Approach
# This function uses the return-data pattern to avoid BATS scoping issues with
# namerefs/eval. Instead of modifying the caller's array directly, it returns data
# that the caller can use to populate their array using json_populate_array_from_output().
#
# Usage example:
#   output=$(json_to_array "$json")
#   count=$(json_populate_array_from_output "my_array" "$output")
json_to_array() {
	local json="$1"

	if [[ -z "$json" ]]; then
		echo "0"
		return 1
	fi

	# Validate input and get elements
	local elements
	if ! elements=$(echo "$json" | jq -r '.[]' 2>/dev/null); then
		echo "0"
		return 1
	fi

	# Count elements (handle empty case - jq returns nothing, echo adds newline)
	local count
	if [[ -z "$elements" ]]; then
		count=0
	else
		count=$(echo "$elements" | wc -l | tr -d ' ')
	fi

	# Output count first, then elements
	echo "$count"
	echo "$elements"

	return 0
}

# Convert a Bash array to JSON array
# Arguments:
#   var_name: Name of Bash array variable
# Returns:
#   JSON array string
#
# PATTERN: Read-Only Nameref (acceptable)
# This function uses nameref only to read array values, not to modify them.
# Read-only nameref is acceptable and does not cause scoping issues.
array_to_json() {
	local var_name="$1"

	if [[ -z "$var_name" ]]; then
	echo "[]"
	return 1
	fi

	local -n arr="$var_name"
	local json_items=()

	for item in "${arr[@]}"; do
	# Escape the item for JSON
	local escaped_item
	escaped_item=$(json_escape "$item")
	json_items+=("\"$escaped_item\"")
	done

	local joined
	joined=$(IFS=','; echo "${json_items[*]}")
	echo "[$joined]"
}

# Convert an associative array to JSON object
# Arguments:
#   var_name: Name of Bash associative array variable
# Returns:
#   JSON object string
#
# PATTERN: Read-Only Nameref (acceptable)
# This function uses nameref only to read associative array values, not to modify them.
# Read-only nameref is acceptable and does not cause scoping issues.
assoc_array_to_json() {
	local var_name="$1"

	if [[ -z "$var_name" ]]; then
	echo "{}"
	return 1
	fi

	local -n assoc_arr="$var_name"
	local json_pairs=()

	for key in "${!assoc_arr[@]}"; do
	local escaped_key
	escaped_key=$(json_escape "$key")
	local escaped_value
	escaped_value=$(json_escape "${assoc_arr[$key]}")
	json_pairs+=("\"$escaped_key\":\"$escaped_value\"")
	done

	local joined
	joined=$(IFS=','; echo "${json_pairs[*]}")
	echo "{$joined}"
}

# ============================================================================
# Utility Functions
# ============================================================================

# Escape a string for use in JSON
# Arguments:
#   string: String to escape
# Returns:
#   Escaped string
json_escape() {
	local string="$1"

	# Escape backslashes first, then quotes
	string="${string//\\/\\\\}"
	string="${string//\"/\\\"}"
	string="${string//$'\n'/\\n}"
	string="${string//$'\r'/\\r}"
	string="${string//$'\t'/\\t}"

	echo "$string"
}

# ============================================================================
# Specialized Conversion Functions (for Suitey data structures)
# ============================================================================

# Convert build requirements JSON to Bash array structure
# Arguments:
#   json: Build requirements JSON array
# Returns:
#   Returns: first line = count, subsequent lines = JSON requirement strings
#
# PATTERN: Return-Data Approach
# This function uses the return-data pattern to avoid BATS scoping issues with
# namerefs/eval. Instead of modifying the caller's array directly, it returns data
# that the caller can use to populate their array using json_populate_array_from_output().
#
# Usage example:
#   output=$(build_requirements_json_to_array "$json")
#   count=$(json_populate_array_from_output "my_array" "$output")
build_requirements_json_to_array() {
	local json="$1"

	if [[ -z "$json" ]]; then
		echo "0"
		return 1
	fi

	# Validate input
	if ! json_validate "$json" || ! json_is_array "$json"; then
		echo "0"
		return 1
	fi

	# Get array length
	local total_count
	total_count=$(json_array_length "$json")

	# Count and output non-null requirements
	local count=0
	for ((i=0; i<total_count; i++)); do
		local req_json
		req_json=$(json_array_get "$json" "$i")
		if [[ -n "$req_json" ]] && [[ "$req_json" != "null" ]]; then
			((++count))  # Use pre-increment to avoid 0 evaluation issue with set -e
		fi
	done

	# Output count first
	echo "$count"

	# Extract each requirement and output (compacted to single line)
	for ((i=0; i<total_count; i++)); do
		local req_json
		req_json=$(json_array_get "$json" "$i")
		if [[ -n "$req_json" ]] && [[ "$req_json" != "null" ]]; then
			# Compact JSON to single line for easier parsing
			echo "$req_json" | jq -c .
		fi
	done

	return 0
}

# ============================================================================
# Return-Data Pattern Helper Function
# ============================================================================
#
# Helper function to populate a Bash array from return-data format
# This is a reusable pattern for functions that return data instead of modifying
# arrays directly (to avoid BATS scoping issues).
#
# Arguments:
#   array_name: Name of Bash array variable to populate
#   output: Output from a return-data function (first line is count, rest are array elements)
# Returns:
#   Populates the named array and returns the count
#
# Usage example:
#   output=$(_json_to_array_return_data "$json")
#   count=$(json_populate_array_from_output "my_array" "$output")
json_populate_array_from_output() {
	local array_name="$1"
	local output="$2"

	local count
	count=$(echo "$output" | head -n 1)

	# Populate array from remaining lines (only if count > 0)
	if [[ "$count" -gt 0 ]]; then
		# Unset any local declaration first, then declare as global
		# This allows us to modify arrays even if caller declared them locally
		eval "unset ${array_name} 2>/dev/null || true"
		eval "declare -g -a ${array_name}"
		# Populate using eval (to avoid BATS scoping issues with nameref)
		# Use printf %q for safe quoting (matches pattern from shell.bats tests)
		local idx=0
		while IFS= read -r element; do
			[[ -z "$element" ]] && continue
			local safe_element
			safe_element=$(printf '%q' "$element")
			# For indexed arrays, use numeric index (no quotes needed) and safe_element
			eval "${array_name}[$idx]=$safe_element"
			((++idx))  # Use pre-increment to avoid 0 evaluation issue with set -e
		done < <(echo "$output" | tail -n +2)
	fi

	echo "$count"
	return 0
}

# Convert dependency analysis associative array to JSON
# Arguments:
#   var_name: Name of associative array variable
# Returns:
#   JSON object with tier information
#
# PATTERN: Read-Only Nameref (acceptable)
# This function uses nameref only to read associative array values, not to modify them.
# Read-only nameref is acceptable and does not cause scoping issues.
dependency_analysis_array_to_json() {
	local var_name="$1"

	if [[ -z "$var_name" ]]; then
	echo "{}"
	return 1
	fi

	local -n analysis="$var_name"
	local json="{"

	# Add each key-value pair
	local first=true
	for key in "${!analysis[@]}"; do
	if [[ "$first" == "true" ]]; then
	first=false
	else
	json="${json},"
	fi

	local escaped_key
	escaped_key=$(json_escape "$key")
	local escaped_value
	escaped_value=$(json_escape "${analysis[$key]}")

	json="${json}\"$escaped_key\":\"$escaped_value\""
	done

	json="${json}}"
	echo "$json"
}

# Convert framework detection results to JSON (used by detect_frameworks)
# Arguments:
#   frameworks_array: Array of detected framework names
#   details_map: Associative array of framework details
#   binary_map: Associative array of binary status
#   warnings_array: Array of warning messages
#   errors_array: Array of error messages
# Returns:
#   Complete JSON detection results object
framework_detection_results_to_json() {
	local frameworks_array="$1"
	local details_map="$2"
	local binary_map="$3"
	local warnings_array="$4"
	local errors_array="$5"

	local frameworks_json
	frameworks_json=$(array_to_json "$frameworks_array")

	local details_json
	details_json=$(assoc_array_to_json "$details_map")

	local binary_json
	binary_json=$(assoc_array_to_json "$binary_map")

	local warnings_json
	warnings_json=$(array_to_json "$warnings_array")

	local errors_json
	errors_json=$(array_to_json "$errors_array")

	# documented: Outputting framework detection results as JSON
	echo "{\"framework_list\":$frameworks_json,\"framework_details\":$details_json," \
		"\"binary_status\":$binary_json,\"warnings\":$warnings_json,\"errors\":$errors_json}"
}

# ============================================================================
# Caching and Performance Functions (Phase 4)
# ============================================================================

# Cache for frequently accessed JSON values
declare -A JSON_CACHE=()

# Get a cached JSON value
# Arguments:
#   cache_key: Unique key for this JSON+path combination
#   json: JSON string
#   path: jq path
# Returns:
#   Cached value if available, otherwise computed value
json_get_cached() {
	local cache_key="$1"
	local json="$2"
	local path="$3"

	# Check cache first
	if [[ -v JSON_CACHE["$cache_key"] ]]; then
	echo "${JSON_CACHE["$cache_key"]}"
	return 0
	fi

	# Compute and cache
	local value
	value=$(json_get "$json" "$path")
	local exit_code=$?

	if [[ $exit_code -eq 0 ]]; then
	JSON_CACHE["$cache_key"]="$value"
	fi

	echo "$value"
	return $exit_code
}

# Clear the JSON cache (useful for memory management)
json_clear_cache() {
	JSON_CACHE=()
}

# ============================================================================
# Source: src/adapter_registry_helpers.sh
# ============================================================================
# ============================================================================
# Adapter Registry Helper Functions
# ============================================================================
#

# ============================================================================
# Variable Declarations (for set -u compatibility)
# ============================================================================
# Declare variables early to prevent "unbound variable" errors when set -u is enabled
# These are declared here as a safety measure, even though they're also declared in adapter_registry.sh
# This ensures the variables exist if adapter_registry_helpers.sh is sourced before adapter_registry.sh
# Use eval to avoid errors if variable is already declared
eval "declare -A ADAPTER_REGISTRY_CAPABILITIES 2>/dev/null || true" || true

# ============================================================================
# Helper Functions
# ============================================================================

# ============================================================================
# Return-Data Pattern Helper Function
# ============================================================================
#
# Helper function to populate an associative array from return-data format
# This is a reusable pattern for functions that return data instead of modifying
# arrays directly (to avoid BATS scoping issues).
#
# PATTERN: Return-Data Approach
# This helper implements the "return-data" pattern to avoid BATS scoping issues with
# namerefs/eval. Instead of modifying the caller's array directly, functions return data
# that the caller can use to populate their array.
#
# When to use return-data pattern:
#   - Function needs to populate caller's array
#   - Function is tested in BATS
#   - Function processes data from files/external sources
#   - You want explicit control over array population
#
# When nameref is acceptable:
#   - Function only reads from arrays (not modifies)
#   - Function modifies global arrays directly
#   - Function is not tested in BATS or tests pass
#   - Performance is critical (nameref is slightly faster)
#
# Arguments:
#   array_name: Name of associative array to populate
#   output: Output from a return-data function (first line is count, rest are key=value)
# Returns:
#   Populates the named array and returns the count
#
# Usage example:
#   output=$(_adapter_registry_load_array_from_file "array_name" "$file")
#   count=$(_adapter_registry_populate_array_from_output "array_name" "$output")
_adapter_registry_populate_array_from_output() {
	local array_name="$1"
	local output="$2"
	
	local count
	count=$(echo "$output" | head -n 1)
	
	# Populate array from remaining lines (only if count > 0)
	if [[ "$count" -gt 0 ]]; then
		while IFS='=' read -r key value || [[ -n "$key" ]]; do
			[[ -z "$key" ]] && continue
			eval "${array_name}[\"$key\"]=\"$value\""
		done < <(echo "$output" | tail -n +2)
	fi
	
	echo "$count"
	return 0
}

# Helper: Determine the base directory for registry files
_adapter_registry_determine_base_dir() {
	# Determine the base directory - prioritize TEST_ADAPTER_REGISTRY_DIR if set
	if [[ -n "${TEST_ADAPTER_REGISTRY_DIR:-}" ]]; then
		# TEST_ADAPTER_REGISTRY_DIR takes precedence for test consistency
		echo "$TEST_ADAPTER_REGISTRY_DIR"
	elif [[ -n "${REGISTRY_BASE_DIR:-}" ]] && [[ -d "${REGISTRY_BASE_DIR:-}" ]]; then
		# Use existing REGISTRY_BASE_DIR if it's a valid directory
		echo "$REGISTRY_BASE_DIR"
	else
		# Fall back to TMPDIR
		echo "${TMPDIR:-/tmp}"
	fi
}

# Helper: Ensure directory exists and is writable
_adapter_registry_ensure_directory() {
	local dir="$1"

	if ! mkdir -p "$dir" 2>&1; then
		echo "ERROR: Failed to create registry directory: $dir" >&2  # documented: Directory creation failed
		return 1
	fi
	return 0
}

# Helper: Base64 encode a value with platform fallbacks
_adapter_registry_encode_value() {
	local value="$1"
	local encoded_value=""

	# Base64 encode: try -w 0 (GNU) first, fall back to -b 0 (macOS) or no flag with tr
	if encoded_value=$(echo -n "$value" | base64 -w 0 2>/dev/null) && \
		[[ -n "$encoded_value" ]]; then
		: # Success with -w 0
	elif encoded_value=$(echo -n "$value" | base64 -b 0 2>/dev/null) && \
		[[ -n "$encoded_value" ]]; then
		: # Success with -b 0
	elif encoded_value=$(echo -n "$value" | base64 | tr -d '\n') && \
		[[ -n "$encoded_value" ]]; then
		: # Success with base64 + tr
	fi

	if [[ -z "$encoded_value" ]]; then
		echo "ERROR: Failed to encode value" >&2  # documented: Base64 encoding failed
		return 1
	fi

	echo "$encoded_value"
	return 0
}

# Helper: Base64 decode a value with platform fallbacks
_adapter_registry_decode_value() {
	local encoded_value="$1"
	local decoded_value=""

	# Try different base64 decoding variants
	# Check both exit code and non-empty output
	if decoded_value=$(echo -n "$encoded_value" | base64 -d 2>/dev/null); then
		if [[ -n "$decoded_value" ]]; then
			echo "$decoded_value"
			return 0
		fi
	elif decoded_value=$(echo -n "$encoded_value" | base64 --decode 2>/dev/null); then
		if [[ -n "$decoded_value" ]]; then
			echo "$decoded_value"
			return 0
		fi
	fi

	# All attempts failed
	echo ""
	return 1
}

# Helper: Save an associative array to a file with base64 encoding
# Uses atomic write: writes to temp file first, then renames atomically
_adapter_registry_save_array_to_file() {
	local array_name="$1"
	local file_path="$2"
	local dir_path
	dir_path=$(dirname "$file_path")

	# Get the array reference dynamically
	local -n array_ref="$array_name"

	# Ensure directory exists before writing (defensive check)
	# Don't suppress stderr - we need to see actual errors
	if ! mkdir -p "$dir_path" 2>&1; then
		echo "ERROR: Failed to create directory for registry file: $dir_path" >&2
		return 1
	fi

	# Verify directory actually exists after creation
	if [[ ! -d "$dir_path" ]]; then
		echo "ERROR: Directory does not exist after creation: $dir_path" >&2
		return 1
	fi

	# Create temporary file in the same directory for atomic write
	# Re-ensure directory exists right before mktemp to handle race conditions in parallel execution
	mkdir -p "$dir_path" 2>/dev/null || true
	local temp_file
	temp_file=$(mktemp -p "$dir_path" "${file_path##*/}.tmp.XXXXXX" 2>&1)
	local mktemp_exit=$?
	if [[ $mktemp_exit -ne 0 ]] || [[ ! -f "$temp_file" ]]; then
		# If mktemp failed due to missing directory, try creating directory again and retry once
		if [[ "$temp_file" == *"No such file or directory"* ]] && [[ -n "$dir_path" ]]; then
			mkdir -p "$dir_path" 2>/dev/null || true
			temp_file=$(mktemp -p "$dir_path" "${file_path##*/}.tmp.XXXXXX" 2>&1)
			mktemp_exit=$?
		fi
		if [[ $mktemp_exit -ne 0 ]] || [[ ! -f "$temp_file" ]]; then
			echo "ERROR: Failed to create temporary file for atomic write: $temp_file" >&2
			return 1
		fi
	fi

	# Write all data to temporary file
	for key in "${!array_ref[@]}"; do
		local value="${array_ref[$key]}"
		# Skip empty values (shouldn't happen, but defensive)
		if [[ -z "$value" ]]; then
			# Silently skip empty values (they shouldn't be in the array anyway)
			continue
		fi
		local encoded_value
		if ! encoded_value=$(_adapter_registry_encode_value "$value"); then
			# Clean up temp file on error
			rm -f "$temp_file"
			echo "ERROR: Failed to encode value for key '$key': '$value'" >&2
			return 1
		fi
		echo "$key=$encoded_value" >> "$temp_file" || {
			rm -f "$temp_file"
			echo "ERROR: Failed to write to temporary file: $temp_file" >&2
			return 1
		}
	done

	# Atomically rename temp file to final file (atomic on most filesystems)
	if ! mv "$temp_file" "$file_path" 2>&1; then
		# Clean up temp file if rename failed
		rm -f "$temp_file"
		echo "ERROR: Failed to atomically rename temporary file to: $file_path" >&2
		return 1
	fi

	return 0
}

# Helper: Load an associative array from a file with base64 decoding
#
# PATTERN: Return-Data Approach
# This function uses the "return-data" pattern to avoid BATS scoping issues with
# namerefs/eval. Instead of modifying the caller's array directly, it returns data
# that the caller can use to populate their array.
#
# When to use return-data pattern:
#   - Function needs to populate caller's array
#   - Function is tested in BATS
#   - Function processes data from files/external sources
#   - You want explicit control over array population
#
# When nameref is acceptable:
#   - Function only reads from arrays (not modifies)
#   - Function modifies global arrays directly
#   - Function is not tested in BATS or tests pass
#   - Performance is critical (nameref is slightly faster)
#
# Returns: first line is count, subsequent lines are key=value pairs (decoded)
# Caller should read first line for count, then process remaining lines to populate array
#
# Usage example:
#   output=$(_adapter_registry_load_array_from_file "array_name" "$file")
#   count=$(echo "$output" | head -n 1)
#   if [[ "$count" -gt 0 ]]; then
#     while IFS='=' read -r key value || [[ -n "$key" ]]; do
#       [[ -z "$key" ]] && continue
#       array["$key"]="$value"
#     done < <(echo "$output" | tail -n +2)
#   fi
_adapter_registry_load_array_from_file() {
	local array_name="$1"
	local file_path="$2"

	if [[ ! -f "$file_path" ]]; then
		echo "0"
		return 0
	fi

	local loaded_count=0
	local line_key
	local line_encoded_value
	local output_lines=""
	
	# Process file and build output
	while IFS= read -r line || [[ -n "$line" ]]; do
		# Skip empty lines
		[[ -z "$line" ]] && continue

		# Split on first '=' only (since base64 can contain '=')
		line_key="${line%%=*}"
		line_encoded_value="${line#*=}"

		# Skip malformed entries
		if [[ -n "$line_key" ]] && [[ -n "$line_encoded_value" ]]; then
			local decoded_value
			local decode_exit
			decoded_value=$(_adapter_registry_decode_value "$line_encoded_value" 2>/dev/null)
			decode_exit=$?
			if [[ $decode_exit -eq 0 ]] && [[ -n "$decoded_value" ]]; then
				# Buffer the output
				output_lines+="${line_key}=${decoded_value}"$'\n'
				loaded_count=$((loaded_count + 1))
			else
				# documented: Base64 decode failed, skipping corrupted registry entry
				echo "WARNING: Failed to decode base64 value for key '$line_key', skipping entry" >&2
			fi
		fi
	done < "$file_path"

	# Output count first, then data
	echo "$loaded_count"
	echo -n "$output_lines"
	return 0
}

# Helper: Save order array to file
# Uses atomic write: writes to temp file first, then renames atomically
_adapter_registry_save_order() {
	local file_path="$1"
	local dir_path
	dir_path=$(dirname "$file_path")

	# Ensure directory exists before writing (defensive check)
	# Don't suppress stderr - we need to see actual errors
	if ! mkdir -p "$dir_path" 2>&1; then
		echo "ERROR: Failed to create directory for order file: $dir_path" >&2
		return 1
	fi

	# Verify directory actually exists after creation
	if [[ ! -d "$dir_path" ]]; then
		echo "ERROR: Directory does not exist after creation: $dir_path" >&2
		return 1
	fi

	# Create temporary file in the same directory for atomic write
	# Re-ensure directory exists right before mktemp to handle race conditions in parallel execution
	mkdir -p "$dir_path" 2>/dev/null || true
	local temp_file
	temp_file=$(mktemp -p "$dir_path" "${file_path##*/}.tmp.XXXXXX" 2>&1)
	local mktemp_exit=$?
	if [[ $mktemp_exit -ne 0 ]] || [[ ! -f "$temp_file" ]]; then
		# If mktemp failed due to missing directory, try creating directory again and retry once
		if [[ "$temp_file" == *"No such file or directory"* ]] && [[ -n "$dir_path" ]]; then
			mkdir -p "$dir_path" 2>/dev/null || true
			temp_file=$(mktemp -p "$dir_path" "${file_path##*/}.tmp.XXXXXX" 2>&1)
			mktemp_exit=$?
		fi
		if [[ $mktemp_exit -ne 0 ]] || [[ ! -f "$temp_file" ]]; then
			echo "ERROR: Failed to create temporary file for atomic write: $temp_file" >&2
			return 1
		fi
	fi

	# Write all data to temporary file
	if ! printf '%s\n' "${ADAPTER_REGISTRY_ORDER[@]}" > "$temp_file" 2>&1; then
		rm -f "$temp_file"
		echo "ERROR: Failed to write to temporary order file: $temp_file" >&2
		return 1
	fi

	# Atomically rename temp file to final file (atomic on most filesystems)
	if ! mv "$temp_file" "$file_path" 2>&1; then
		# Clean up temp file if rename failed
		rm -f "$temp_file"
		echo "ERROR: Failed to atomically rename temporary file to: $file_path" >&2  # documented: Order file write failed
		return 1
	fi
	return 0
}

# Helper: Save initialized flag to file
# Uses atomic write: writes to temp file first, then renames atomically
_adapter_registry_save_initialized() {
	local file_path="$1"
	local dir_path
	dir_path=$(dirname "$file_path")

	# Ensure directory exists before writing (defensive check)
	# Don't suppress stderr - we need to see actual errors
	if ! mkdir -p "$dir_path" 2>&1; then
		echo "ERROR: Failed to create directory for init file: $dir_path" >&2
		return 1
	fi

	# Verify directory actually exists after creation
	if [[ ! -d "$dir_path" ]]; then
		echo "ERROR: Directory does not exist after creation: $dir_path" >&2
		return 1
	fi

	# Create temporary file in the same directory for atomic write
	# Re-ensure directory exists right before mktemp to handle race conditions in parallel execution
	mkdir -p "$dir_path" 2>/dev/null || true
	local temp_file
	temp_file=$(mktemp -p "$dir_path" "${file_path##*/}.tmp.XXXXXX" 2>&1)
	local mktemp_exit=$?
	if [[ $mktemp_exit -ne 0 ]] || [[ ! -f "$temp_file" ]]; then
		# If mktemp failed due to missing directory, try creating directory again and retry once
		if [[ "$temp_file" == *"No such file or directory"* ]] && [[ -n "$dir_path" ]]; then
			mkdir -p "$dir_path" 2>/dev/null || true
			temp_file=$(mktemp -p "$dir_path" "${file_path##*/}.tmp.XXXXXX" 2>&1)
			mktemp_exit=$?
		fi
		if [[ $mktemp_exit -ne 0 ]] || [[ ! -f "$temp_file" ]]; then
			echo "ERROR: Failed to create temporary file for atomic write: $temp_file" >&2
			return 1
		fi
	fi

	# Write data to temporary file
	if ! echo "$ADAPTER_REGISTRY_INITIALIZED" > "$temp_file" 2>&1; then
		rm -f "$temp_file"
		echo "ERROR: Failed to write to temporary init file: $temp_file" >&2
		return 1
	fi

	# Atomically rename temp file to final file (atomic on most filesystems)
	if ! mv "$temp_file" "$file_path" 2>&1; then
		# Clean up temp file if rename failed
		rm -f "$temp_file"
		echo "ERROR: Failed to atomically rename temporary file to: $file_path" >&2
		return 1
	fi
	return 0
}

# Helper: Determine file locations and update globals
_adapter_registry_determine_file_locations() {
	# If TEST_ADAPTER_REGISTRY_DIR is set, always use it (for test consistency)
	local registry_base_dir
	if [[ -n "${TEST_ADAPTER_REGISTRY_DIR:-}" ]]; then
		registry_base_dir="$TEST_ADAPTER_REGISTRY_DIR"
	else
		# Re-evaluate REGISTRY_BASE_DIR to use current TEST_ADAPTER_REGISTRY_DIR value
		registry_base_dir="${TMPDIR:-/tmp}"
	fi

	local registry_file="$registry_base_dir/suitey_adapter_registry"
	local capabilities_file="$registry_base_dir/suitey_adapter_capabilities"
	local order_file="$registry_base_dir/suitey_adapter_order"
	local init_file="$registry_base_dir/suitey_adapter_init"

	# Ensure directory exists before trying to read files
	mkdir -p "$registry_base_dir"

	# Check if we're switching locations BEFORE updating globals
	local switching_locations=false
	if [[ -n "${ADAPTER_REGISTRY_FILE:-}" ]] && [[ "$registry_file" != "${ADAPTER_REGISTRY_FILE:-}" ]]; then
		switching_locations=true
	fi

	# Always update global variables when TEST_ADAPTER_REGISTRY_DIR is set,
	# or if registry file exists in the new location, or if globals haven't been set yet
	if [[ -n "${TEST_ADAPTER_REGISTRY_DIR:-}" ]] || \
		[[ -f "$registry_file" ]] || \
		[[ ! -f "${ADAPTER_REGISTRY_FILE:-/nonexistent}" ]]; then
		REGISTRY_BASE_DIR="$registry_base_dir"
		ADAPTER_REGISTRY_FILE="$registry_file"
		ADAPTER_REGISTRY_CAPABILITIES_FILE="$capabilities_file"
		ADAPTER_REGISTRY_ORDER_FILE="$order_file"
		ADAPTER_REGISTRY_INIT_FILE="$init_file"
	fi

	# Return the actual file paths
	echo "$registry_file"
	echo "$capabilities_file"
	echo "$order_file"
	echo "$init_file"
}

# Helper: Determine if state should be reloaded
_adapter_registry_should_reload() {
	local registry_file="$1"
	local capabilities_file="$2"
	local switching_locations="$3"

	# Reload if the registry file exists (to load latest state from disk),
	# or if we're switching to a different file location
	if [[ -f "$registry_file" ]]; then
		# File exists - reload to get latest state
		echo "true"
	elif [[ "$switching_locations" == "true" ]]; then
		# Switching locations - clear to start fresh
		echo "true"
	else
		echo "false"
	fi
}

# Helper: Rebuild capabilities index from loaded adapters
_adapter_registry_rebuild_capabilities() {
	local capabilities_loaded="$1"
	local switching_locations="$2"
	local capabilities_file="$3"

	# Rebuild capabilities index from loaded adapters only if:
	# 1. Capabilities file doesn't exist or is empty (capabilities_loaded is false)
	# 2. We're switching locations (need to rebuild from scratch)
	# 3. The capabilities file exists but is empty
	# This prevents unnecessary rebuilds on every load_state() call, but ensures
	# consistency when files are missing or when switching locations
	if [[ ${#ADAPTER_REGISTRY[@]} -gt 0 ]]; then
		local should_rebuild_capabilities=false

		if [[ "$capabilities_loaded" == "false" ]]; then
			# No capabilities file or file is empty - rebuild from adapters
			should_rebuild_capabilities=true
		elif [[ "$switching_locations" == "true" ]]; then
			# Switching locations - rebuild to ensure consistency
			should_rebuild_capabilities=true
		elif [[ ! -v ADAPTER_REGISTRY_CAPABILITIES ]] || [[ ${#ADAPTER_REGISTRY_CAPABILITIES[@]} -eq 0 ]] && [[ -f "$capabilities_file" ]]; then
			# Capabilities file exists but is empty - rebuild
			should_rebuild_capabilities=true
		fi

		if [[ "$should_rebuild_capabilities" == "true" ]]; then
			# Clear and rebuild from scratch
			ADAPTER_REGISTRY_CAPABILITIES=()
			for adapter_id in "${ADAPTER_REGISTRY_ORDER[@]}"; do
				if [[ -v ADAPTER_REGISTRY["$adapter_id"] ]]; then
					adapter_registry_index_capabilities "$adapter_id" "${ADAPTER_REGISTRY["$adapter_id"]}"
				fi
			done
		fi
	fi
}

# Helper: Parse file paths from helper output
_adapter_registry_parse_file_paths() {
	local file_paths="$1"
	echo "$file_paths" | sed -n '1p'
	echo "$file_paths" | sed -n '2p'
	echo "$file_paths" | sed -n '3p'
	echo "$file_paths" | sed -n '4p'
}

# Helper: Load order array from file with filtering
_adapter_registry_load_order_array() {
	local order_file="$1"
	if [[ -f "$order_file" ]]; then
		mapfile -t ADAPTER_REGISTRY_ORDER < "$order_file"
		# Filter out empty lines and trim spaces (avoid command substitution for BATS compatibility)
		local filtered_array=()
		local element
		for element in "${ADAPTER_REGISTRY_ORDER[@]}"; do
			# Trim leading/trailing spaces
			local trimmed="${element#"${element%%[![:space:]]*}"}"  # Remove leading spaces
			trimmed="${trimmed%"${trimmed##*[![:space:]]}"}"  # Remove trailing spaces
			# Only add non-empty elements
			[[ -n "$trimmed" ]] && filtered_array+=("$trimmed")
		done
		ADAPTER_REGISTRY_ORDER=("${filtered_array[@]}")
	fi
}

# Helper: Load order array from file using return-data pattern
# Returns: count on first line, then one identifier per line
_adapter_registry_load_order_from_file() {
	local order_file="$1"
	
	if [[ ! -f "$order_file" ]]; then
		echo "0"  # Return count of 0 if file doesn't exist
		return 0
	fi
	
	# Read file and filter out empty lines
	local filtered_lines=()
	while IFS= read -r line || [[ -n "$line" ]]; do
		# Trim leading/trailing spaces
		local trimmed="${line#"${line%%[![:space:]]*}"}"
		trimmed="${trimmed%"${trimmed##*[![:space:]]}"}"
		# Only add non-empty lines
		[[ -n "$trimmed" ]] && filtered_lines+=("$trimmed")
	done < "$order_file"
	
	# Return count first, then data (consistent with array loading pattern)
	echo "${#filtered_lines[@]}"
	printf '%s\n' "${filtered_lines[@]}"
	return 0
}

# Helper: Perform reload operations
_adapter_registry_perform_reload() {
	local actual_registry_file="$1"
	local actual_capabilities_file="$2"
	local actual_order_file="$3"
	local switching_locations="$4"

	# Clear arrays before loading to ensure clean state from file
	ADAPTER_REGISTRY=()
	# Only clear capabilities if we're going to load from file
	# This prevents losing in-memory state when file doesn't exist
	if [[ -f "$actual_capabilities_file" ]] || [[ "$switching_locations" == "true" ]]; then
		ADAPTER_REGISTRY_CAPABILITIES=()
	fi
	ADAPTER_REGISTRY_ORDER=()

	# Load arrays from files using return-data pattern (manual population for BATS compatibility)
	local registry_output
	registry_output=$(_adapter_registry_load_array_from_file "ADAPTER_REGISTRY" "$actual_registry_file")
	local registry_count
	registry_count=$(echo "$registry_output" | head -n 1)
	# Manually populate registry array from output
	if [[ "$registry_count" -gt 0 ]]; then
		while IFS='=' read -r key value || [[ -n "$key" ]]; do
			[[ -z "$key" ]] && continue
			ADAPTER_REGISTRY["$key"]="$value"
		done < <(echo "$registry_output" | tail -n +2)
	fi

	local capabilities_loaded=false
	if [[ -f "$actual_capabilities_file" ]]; then
		local capabilities_output
		capabilities_output=$(_adapter_registry_load_array_from_file "ADAPTER_REGISTRY_CAPABILITIES" "$actual_capabilities_file")
		local loaded_count
		loaded_count=$(echo "$capabilities_output" | head -n 1)
		# Manually populate capabilities array from output
		if [[ "$loaded_count" -gt 0 ]]; then
			while IFS='=' read -r key value || [[ -n "$key" ]]; do
				[[ -z "$key" ]] && continue
				ADAPTER_REGISTRY_CAPABILITIES["$key"]="$value"
			done < <(echo "$capabilities_output" | tail -n +2)
		fi
		[[ "$loaded_count" -gt 0 ]] && capabilities_loaded=true
	fi

	_adapter_registry_load_order_array "$actual_order_file"
	_adapter_registry_rebuild_capabilities "$capabilities_loaded" "$switching_locations" "$actual_capabilities_file"
}

# ============================================================================
# Source: src/adapter_registry.sh
# ============================================================================
# ============================================================================
# Adapter Registry
# ============================================================================
#

# Source JSON helper functions
if [[ -f "json_helpers.sh" ]]; then
	source "json_helpers.sh"
elif [[ -f "src/json_helpers.sh" ]]; then
	source "src/json_helpers.sh"
elif [[ -f "../src/json_helpers.sh" ]]; then
	source "../src/json_helpers.sh"
fi

# Source adapter registry helper functions
if [[ -f "adapter_registry_helpers.sh" ]]; then
	source "adapter_registry_helpers.sh"
elif [[ -f "src/adapter_registry_helpers.sh" ]]; then
	source "src/adapter_registry_helpers.sh"
elif [[ -f "../src/adapter_registry_helpers.sh" ]]; then
	source "../src/adapter_registry_helpers.sh"
fi

# Registry Data Structures
declare -A ADAPTER_REGISTRY                    # Maps adapter identifier -> metadata JSON
declare -A ADAPTER_REGISTRY_CAPABILITIES       # Maps capability -> comma-separated adapter list
ADAPTER_REGISTRY_INITIALIZED=false            # Tracks whether registry has been initialized
ADAPTER_REGISTRY_ORDER=()                     # Preserves registration order

# Registry Persistence (for testing)
# These variables are computed dynamically when needed to avoid race conditions
# in parallel test execution. They should NOT be initialized at module load time
# because TEST_ADAPTER_REGISTRY_DIR may not be set yet.
REGISTRY_BASE_DIR=""
ADAPTER_REGISTRY_FILE=""
ADAPTER_REGISTRY_CAPABILITIES_FILE=""
ADAPTER_REGISTRY_ORDER_FILE=""
ADAPTER_REGISTRY_INIT_FILE=""

# ============================================================================
# Adapter Registry Functions
# ============================================================================

# Save registry state to files (for testing persistence)
adapter_registry_save_state() {
	# Determine base directory for registry files
	local actual_base_dir
	actual_base_dir=$(_adapter_registry_determine_base_dir) || return 1

	# Ensure directory exists and is writable
	_adapter_registry_ensure_directory "$actual_base_dir" || return 1

	# Set file paths based on the actual base directory
	local registry_file="$actual_base_dir/suitey_adapter_registry"
	local capabilities_file="$actual_base_dir/suitey_adapter_capabilities"
	local order_file="$actual_base_dir/suitey_adapter_order"
	local init_file="$actual_base_dir/suitey_adapter_init"

	# Always update global variables to match the actual paths we're using
	# This ensures load_state() uses the same directory as save_state()
	REGISTRY_BASE_DIR="$actual_base_dir"
	ADAPTER_REGISTRY_FILE="$registry_file"
	ADAPTER_REGISTRY_CAPABILITIES_FILE="$capabilities_file"
	ADAPTER_REGISTRY_ORDER_FILE="$order_file"
	ADAPTER_REGISTRY_INIT_FILE="$init_file"

	# Save arrays to files
	_adapter_registry_save_array_to_file "ADAPTER_REGISTRY" "$registry_file" || return 1
	_adapter_registry_save_array_to_file "ADAPTER_REGISTRY_CAPABILITIES" "$capabilities_file" || return 1
	_adapter_registry_save_order "$order_file" || return 1
	_adapter_registry_save_initialized "$init_file" || return 1
}

# Helper: Parse file paths from helper output
_adapter_registry_parse_file_paths() {
	local file_paths="$1"
	echo "$file_paths" | sed -n '1p'
	echo "$file_paths" | sed -n '2p'
	echo "$file_paths" | sed -n '3p'
	echo "$file_paths" | sed -n '4p'
}

# Helper: Load order array from file with filtering
_adapter_registry_load_order_array() {
	local order_file="$1"
	if [[ -f "$order_file" ]]; then
		mapfile -t ADAPTER_REGISTRY_ORDER < "$order_file"
		# Filter out empty lines
		ADAPTER_REGISTRY_ORDER=("${ADAPTER_REGISTRY_ORDER[@]// /}")  # Remove spaces
		ADAPTER_REGISTRY_ORDER=($(printf '%s\n' "${ADAPTER_REGISTRY_ORDER[@]}" | grep -v '^$'))
	fi
}

# Helper: Perform reload operations (returns data instead of populating arrays)
# Returns: registry_output, capabilities_output, order_output, capabilities_loaded flag
# Format: Line 1 = capabilities_loaded (true/false), Line 2 = switching_locations (true/false),
#         Then registry_output (count + key=value pairs), then capabilities_output, then order_output
_adapter_registry_perform_reload() {
	local actual_registry_file="$1"
	local actual_capabilities_file="$2"
	local actual_order_file="$3"
	local switching_locations="$4"

	# Load data from files using return-data pattern
	local registry_output
	registry_output=$(_adapter_registry_load_array_from_file "ADAPTER_REGISTRY" "$actual_registry_file")
	
	local capabilities_output=""
	local capabilities_loaded=false
	if [[ -f "$actual_capabilities_file" ]]; then
		capabilities_output=$(_adapter_registry_load_array_from_file "ADAPTER_REGISTRY_CAPABILITIES" "$actual_capabilities_file")
		local loaded_count
		loaded_count=$(echo "$capabilities_output" | head -n 1)
		[[ "$loaded_count" -gt 0 ]] && capabilities_loaded=true
	fi
	
	local order_output=""
	if [[ -f "$actual_order_file" ]]; then
		# Load order file content
		order_output=$(cat "$actual_order_file" 2>/dev/null || echo "")
	fi
	
	# Return data: capabilities_loaded flag, switching_locations flag, then outputs
	# Use a delimiter to separate sections
	echo "CAPABILITIES_LOADED:$capabilities_loaded"
	echo "SWITCHING_LOCATIONS:$switching_locations"
	echo "REGISTRY_START"
	echo -n "$registry_output"
	echo "REGISTRY_END"
	echo "CAPABILITIES_START"
	echo -n "$capabilities_output"
	echo "CAPABILITIES_END"
	echo "ORDER_START"
	echo -n "$order_output"
	echo "ORDER_END"
	return 0
}

# Load registry state from files (for testing persistence)
adapter_registry_load_state() {
	# Determine file locations and update globals
	local file_paths
	file_paths=$(_adapter_registry_determine_file_locations)
	local file_paths_array
	mapfile -t file_paths_array < <(_adapter_registry_parse_file_paths "$file_paths")
	local actual_registry_file="${file_paths_array[0]}"
	local actual_capabilities_file="${file_paths_array[1]}"
	local actual_order_file="${file_paths_array[2]}"
	local actual_init_file="${file_paths_array[3]}"

	# Check if we're switching locations BEFORE updating globals (this was done in the helper)
	local switching_locations=false
	if [[ -n "${ADAPTER_REGISTRY_FILE:-}" ]] && [[ "$actual_registry_file" != "${ADAPTER_REGISTRY_FILE:-}" ]]; then
		switching_locations=true
	fi

	# Determine if state should be reloaded
	local should_reload
	should_reload=$(_adapter_registry_should_reload \
		"$actual_registry_file" \
		"$actual_capabilities_file" \
		"$switching_locations")

	if [[ "$should_reload" == "true" ]]; then
		# Get reload data from helper
		local reload_data
		reload_data=$(_adapter_registry_perform_reload \
			"$actual_registry_file" \
			"$actual_capabilities_file" \
			"$actual_order_file" \
			"$switching_locations")
		
		# Parse reload data
		local capabilities_loaded
		capabilities_loaded=$(echo "$reload_data" | grep "^CAPABILITIES_LOADED:" | cut -d: -f2)
		local switching
		switching=$(echo "$reload_data" | grep "^SWITCHING_LOCATIONS:" | cut -d: -f2)
		
		# Extract registry output (between REGISTRY_START and REGISTRY_END)
		local registry_output
		registry_output=$(echo "$reload_data" | sed -n '/^REGISTRY_START$/,/^REGISTRY_END$/p' | sed -e '1d' -e '$d')
		
		# Extract capabilities output (between CAPABILITIES_START and CAPABILITIES_END)
		local capabilities_output
		capabilities_output=$(echo "$reload_data" | sed -n '/^CAPABILITIES_START$/,/^CAPABILITIES_END$/p' | sed -e '1d' -e '$d')
		
		# Extract order output (between ORDER_START and ORDER_END)
		local order_output
		order_output=$(echo "$reload_data" | sed -n '/^ORDER_START$/,/^ORDER_END$/p' | sed -e '1d' -e '$d')
		
		# Ensure arrays are declared as global before populating (BATS compatibility)
		# Unset first to ensure clean state
		eval "unset ADAPTER_REGISTRY 2>/dev/null || true"
		# Declare as associative array (global scope)
		declare -g -A ADAPTER_REGISTRY
		# Clear the array (this preserves the associative type)
		ADAPTER_REGISTRY=()
		
		# Always ensure ADAPTER_REGISTRY_CAPABILITIES is declared (BATS compatibility)
			eval "unset ADAPTER_REGISTRY_CAPABILITIES 2>/dev/null || true"
			eval "declare -g -A ADAPTER_REGISTRY_CAPABILITIES"
			ADAPTER_REGISTRY_CAPABILITIES=()
		
		eval "unset ADAPTER_REGISTRY_ORDER 2>/dev/null || true"
		eval "declare -g -a ADAPTER_REGISTRY_ORDER"
		ADAPTER_REGISTRY_ORDER=()
		
		# Populate registry array from output
		local registry_count
		registry_count=$(echo "$registry_output" | head -n 1)
		# Validate that registry_count is a valid number
		if [[ "$registry_count" =~ ^[0-9]+$ ]] && [[ "$registry_count" -gt 0 ]]; then
			while IFS='=' read -r key value || [[ -n "$key" ]]; do
				[[ -z "$key" ]] && continue
				# Skip if key looks like a delimiter or is invalid
				[[ "$key" == "REGISTRY_START" ]] && continue
				[[ "$key" == "REGISTRY_END" ]] && continue
				[[ "$key" == "CAPABILITIES_START" ]] && continue
				[[ "$key" == "CAPABILITIES_END" ]] && continue
				[[ "$key" == "ORDER_START" ]] && continue
				[[ "$key" == "ORDER_END" ]] && continue
				# Skip if key is purely numeric (likely a count line that wasn't filtered)
				[[ "$key" =~ ^[0-9]+$ ]] && continue
				
				# Clean the value - remove any trailing delimiter strings that might have been included
				value="${value%%CAPABILITIES_END*}"
				value="${value%%REGISTRY_END*}"
				value="${value%%ORDER_END*}"
				# Trim trailing whitespace
				value="${value%"${value##*[![:space:]]}"}"
				
				ADAPTER_REGISTRY["$key"]="$value"
			done < <(echo "$registry_output" | tail -n +2)
		fi

		# Populate capabilities array from output
		if [[ -n "$capabilities_output" ]]; then
			local loaded_count
			loaded_count=$(echo "$capabilities_output" | head -n 1)
			if [[ "$loaded_count" =~ ^[0-9]+$ ]] && [[ "$loaded_count" -gt 0 ]]; then
				while IFS='=' read -r key value || [[ -n "$key" ]]; do
					[[ -z "$key" ]] && continue
					# Skip if key looks like a delimiter or is invalid
					[[ "$key" == "REGISTRY_START" ]] && continue
					[[ "$key" == "REGISTRY_END" ]] && continue
					[[ "$key" == "CAPABILITIES_START" ]] && continue
					[[ "$key" == "CAPABILITIES_END" ]] && continue
					[[ "$key" == "ORDER_START" ]] && continue
					[[ "$key" == "ORDER_END" ]] && continue
					# Skip if key is purely numeric (likely a count line that wasn't filtered)
					[[ "$key" =~ ^[0-9]+$ ]] && continue
					
					# Clean the value - remove any trailing delimiter strings that might have been included
					value="${value%%CAPABILITIES_END*}"
					value="${value%%REGISTRY_END*}"
					value="${value%%ORDER_END*}"
					# Trim trailing whitespace
					value="${value%"${value##*[![:space:]]}"}"
					
					ADAPTER_REGISTRY_CAPABILITIES["$key"]="$value"
				done < <(echo "$capabilities_output" | tail -n +2)
			fi
		fi
		
		# Populate order array from output
		if [[ -n "$order_output" ]]; then
			# Filter out empty lines and delimiter strings
			local filtered_array=()
			local element
			while IFS= read -r element || [[ -n "$element" ]]; do
				# Trim leading/trailing spaces
				local trimmed="${element#"${element%%[![:space:]]*}"}"
				trimmed="${trimmed%"${trimmed##*[![:space:]]}"}"
				# Skip empty lines and delimiter strings
				[[ -z "$trimmed" ]] && continue
				[[ "$trimmed" == "REGISTRY_START" ]] && continue
				[[ "$trimmed" == "REGISTRY_END" ]] && continue
				[[ "$trimmed" == "CAPABILITIES_START" ]] && continue
				[[ "$trimmed" == "CAPABILITIES_END" ]] && continue
				[[ "$trimmed" == "ORDER_START" ]] && continue
				[[ "$trimmed" == "ORDER_END" ]] && continue
				filtered_array+=("$trimmed")
			done < <(echo "$order_output")
			ADAPTER_REGISTRY_ORDER=("${filtered_array[@]}")
		fi
		
		_adapter_registry_rebuild_capabilities "$capabilities_loaded" "$switching" "$actual_capabilities_file"
		
		# Ensure ADAPTER_REGISTRY_FILE is set for duplicate detection
		ADAPTER_REGISTRY_FILE="$actual_registry_file"
	fi
	
	# Always ensure ADAPTER_REGISTRY_FILE is set (even if we didn't reload)
	if [[ -z "${ADAPTER_REGISTRY_FILE:-}" ]]; then
		ADAPTER_REGISTRY_FILE="$actual_registry_file"
	fi

	# Always ensure ADAPTER_REGISTRY_ORDER is declared (BATS compatibility)
	# This is necessary because in subshell contexts, arrays don't persist
	if ! declare -p ADAPTER_REGISTRY_ORDER 2>/dev/null | grep -q '\-a'; then
		eval "unset ADAPTER_REGISTRY_ORDER 2>/dev/null || true"
		declare -g -a ADAPTER_REGISTRY_ORDER
		ADAPTER_REGISTRY_ORDER=()
	fi

	# Always load order array if file exists (using return-data pattern)
	# This ensures it works in subshell contexts where arrays don't persist
	# and ensures order is loaded even if should_reload was false or reload didn't populate it correctly
	# We always reload from file to ensure we have the latest state
	if [[ -f "$actual_order_file" ]]; then
		local order_data
		order_data=$(_adapter_registry_load_order_from_file "$actual_order_file")
		local order_count
		order_count=$(echo "$order_data" | head -n 1)
		
		if [[ "$order_count" =~ ^[0-9]+$ ]] && [[ "$order_count" -gt 0 ]]; then
			# Populate array from returned data (always reload to ensure latest state)
			mapfile -t ADAPTER_REGISTRY_ORDER < <(echo "$order_data" | tail -n +2)
		fi
	fi

	# Always ensure ADAPTER_REGISTRY_CAPABILITIES is declared (BATS compatibility)
	# This is necessary because in subshell contexts, arrays don't persist
	if ! declare -p ADAPTER_REGISTRY_CAPABILITIES 2>/dev/null | grep -q '\-A'; then
		eval "unset ADAPTER_REGISTRY_CAPABILITIES 2>/dev/null || true"
		declare -g -A ADAPTER_REGISTRY_CAPABILITIES
		ADAPTER_REGISTRY_CAPABILITIES=()
	fi

	# Always load capabilities array if file exists (using return-data pattern)
	# This ensures it works in subshell contexts where arrays don't persist
	# and ensures capabilities are loaded even if should_reload was false or reload didn't populate it correctly
	# We always reload from file to ensure we have the latest state
	# Only load if array is empty or if we didn't reload (to avoid overwriting in-memory state unnecessarily)
	# Use safe check for set -u compatibility: check if variable is declared before checking length
	if [[ ! -v ADAPTER_REGISTRY_CAPABILITIES ]] || [[ ${#ADAPTER_REGISTRY_CAPABILITIES[@]} -eq 0 ]] && [[ -f "$actual_capabilities_file" ]]; then
		local capabilities_data
		capabilities_data=$(_adapter_registry_load_array_from_file "ADAPTER_REGISTRY_CAPABILITIES" "$actual_capabilities_file")
		local capabilities_count
		capabilities_count=$(echo "$capabilities_data" | head -n 1)
		
		if [[ "$capabilities_count" =~ ^[0-9]+$ ]] && [[ "$capabilities_count" -gt 0 ]]; then
			# Populate array from returned data (always reload to ensure latest state)
			while IFS='=' read -r key value || [[ -n "$key" ]]; do
				[[ -z "$key" ]] && continue
				# Skip if key looks like a delimiter or is invalid
				[[ "$key" == "REGISTRY_START" ]] && continue
				[[ "$key" == "REGISTRY_END" ]] && continue
				[[ "$key" == "CAPABILITIES_START" ]] && continue
				[[ "$key" == "CAPABILITIES_END" ]] && continue
				[[ "$key" == "ORDER_START" ]] && continue
				[[ "$key" == "ORDER_END" ]] && continue
				# Skip if key is purely numeric (likely a count line that wasn't filtered)
				[[ "$key" =~ ^[0-9]+$ ]] && continue
				
				# Clean the value - remove any trailing delimiter strings that might have been included
				value="${value%%CAPABILITIES_END*}"
				value="${value%%REGISTRY_END*}"
				value="${value%%ORDER_END*}"
				# Trim trailing whitespace
				value="${value%"${value##*[![:space:]]}"}"
				
				ADAPTER_REGISTRY_CAPABILITIES["$key"]="$value"
			done < <(echo "$capabilities_data" | tail -n +2)
		fi
	fi

	# Always try to load ADAPTER_REGISTRY_INITIALIZED if file exists
	if [[ -f "$actual_init_file" ]]; then
		ADAPTER_REGISTRY_INITIALIZED=$(<"$actual_init_file")
	else
		ADAPTER_REGISTRY_INITIALIZED=false
	fi
}

# Clean up registry state files
adapter_registry_cleanup_state() {
	# Compute file paths dynamically to avoid using stale values from module load time
	local file_paths
	file_paths=$(_adapter_registry_determine_file_locations)
	local file_paths_array
	mapfile -t file_paths_array < <(_adapter_registry_parse_file_paths "$file_paths")
	local registry_file="${file_paths_array[0]}"
	local capabilities_file="${file_paths_array[1]}"
	local order_file="${file_paths_array[2]}"
	local init_file="${file_paths_array[3]}"
	
	rm -f "$registry_file" \
		"$capabilities_file" \
		"$order_file" \
		"$init_file"
}

# Initialize/load registry state
# Validate that an adapter implements the required interface
# Arguments:
#   adapter_identifier: The identifier of the adapter to validate
# Returns:
#   0 if valid, 1 if invalid (with error message to stderr)
adapter_registry_validate_interface() {
	adapter_registry_load_state
	local adapter_identifier="$1"

	# List of required interface methods
	local required_methods=(
	"${adapter_identifier}_adapter_detect"
	"${adapter_identifier}_adapter_get_metadata"
	"${adapter_identifier}_adapter_check_binaries"
	"${adapter_identifier}_adapter_discover_test_suites"
	"${adapter_identifier}_adapter_detect_build_requirements"
	"${adapter_identifier}_adapter_get_build_steps"
	"${adapter_identifier}_adapter_execute_test_suite"
	"${adapter_identifier}_adapter_parse_test_results"
	)

	# Check that each required method exists
	for method in "${required_methods[@]}"; do
	if ! command -v "$method" >/dev/null 2>&1; then
	# documented: Required adapter interface method missing
	echo "ERROR: Adapter '$adapter_identifier' is missing required interface method: $method" >&2
	return 1
	fi
	done

	return 0
}

# Extract metadata from an adapter
# Arguments:
#   adapter_identifier: The identifier of the adapter
# Returns:
#   JSON metadata string, or empty string on error
adapter_registry_extract_metadata() {
	local adapter_identifier="$1"
	local metadata_func="${adapter_identifier}_adapter_get_metadata"

	# Call the adapter's metadata function and capture output
	# The function should output JSON metadata to stdout
	# For adapter registration, we call without project_root (general adapter info)
	local metadata_output
	metadata_output=$("$metadata_func" 2>&1)
	local exit_code=$?

	if [[ $exit_code -eq 0 ]] && [[ -n "$metadata_output" ]]; then
	# Function succeeded and produced output, trim trailing newlines
	metadata_output=$(echo -n "$metadata_output" | sed 's/[[:space:]]*$//')
	echo "$metadata_output"
	return 0
	else
	# documented: Adapter metadata function failed or returned empty result
	echo "ERROR: Failed to extract metadata from adapter '$adapter_identifier'" >&2
	if [[ -n "$metadata_output" ]]; then
	echo "$metadata_output" >&2
	fi
	return 1
	fi
}

# Validate adapter metadata structure
# Arguments:
#   adapter_identifier: The identifier of the adapter
#   metadata_json: The JSON metadata string to validate
# Returns:
#   0 if valid, 1 if invalid (with error message to stderr)
adapter_registry_validate_metadata() {
	local adapter_identifier="$1"
	local metadata_json="$2"


	# Required fields that must be present in metadata
	local required_fields=(
		"name" "identifier" "version" "supported_languages"
		"capabilities" "required_binaries" "configuration_files"
	)

	# Check that each required field is present
	for field in "${required_fields[@]}"; do
	if ! json_has_field "$metadata_json" "$field"; then
	# documented: Required metadata field missing
	echo "ERROR: Adapter '$adapter_identifier' metadata is missing required field: $field" >&2
	return 1
	fi
	done

	# Check that identifier matches adapter identifier
	local actual_identifier
	actual_identifier=$(json_get "$metadata_json" ".identifier")
	if [[ "$actual_identifier" != "$adapter_identifier" ]]; then
	# documented: Adapter identifier mismatch in metadata
	echo "ERROR: Adapter '$adapter_identifier' metadata identifier does not match adapter identifier" >&2
	return 1
	fi

	return 0
}

# Index adapter capabilities for efficient lookup
# Arguments:
#   adapter_identifier: The identifier of the adapter
#   metadata_json: The JSON metadata containing capabilities
adapter_registry_index_capabilities() {
	local adapter_identifier="$1"
	local metadata_json="$2"

	# Extract capabilities from metadata JSON
	# Use || : to prevent command substitution from causing script exit (if set -e is enabled)
	# Then validate the result to determine if extraction succeeded
	local capabilities=""
	if [[ -n "$metadata_json" ]]; then
		# Try to extract capabilities - use || : to prevent failure propagation
		capabilities=$(json_get_array "$metadata_json" ".capabilities" 2>/dev/null || :)
		
		# Validate: if metadata_json is non-empty but capabilities extraction might have failed,
		# check if we got a valid result by trying to validate the JSON structure
		# For now, we'll proceed - empty capabilities is valid (adapter has no capabilities)
		# If json_get_array truly failed due to malformed JSON, we'll handle it gracefully
	fi

	# Proceed with indexing if we have capabilities (empty is OK - means no capabilities)
	if [[ -n "$capabilities" ]]; then
		# Ensure ADAPTER_REGISTRY_CAPABILITIES is declared (for set -u compatibility)
		if ! declare -p ADAPTER_REGISTRY_CAPABILITIES 2>/dev/null | grep -q '\-A'; then
			declare -A ADAPTER_REGISTRY_CAPABILITIES
		fi
		# Split capabilities by newline and index each capability
		while IFS= read -r cap; do
			if [[ -n "$cap" ]]; then
				# Add adapter to capability index
				if [[ ! -v ADAPTER_REGISTRY_CAPABILITIES["$cap"] ]]; then
					ADAPTER_REGISTRY_CAPABILITIES["$cap"]="$adapter_identifier"
				else
					ADAPTER_REGISTRY_CAPABILITIES["$cap"]="${ADAPTER_REGISTRY_CAPABILITIES["$cap"]},$adapter_identifier"
				fi
			fi
		done <<< "$capabilities"
	fi

	# Always return success - capability indexing is non-critical
	return 0
}

# Register an adapter in the registry
# Arguments:
#   adapter_identifier: The identifier of the adapter to register
# Returns:
#   0 on success, 1 on error (with error message to stderr)
adapter_registry_register() {
	local adapter_identifier="$1"

	# Load existing state
	adapter_registry_load_state

	# Validate input
	if [[ -z "$adapter_identifier" ]]; then
	echo "ERROR: Cannot register adapter with null or empty identifier" >&2  # documented: Adapter identifier is required
	return 1
	fi

	# Check for identifier conflict
	# Check both in-memory array and file directly (for BATS compatibility)
	# In BATS subshells, arrays may not persist, so always check file (most reliable)
	local identifier_exists=false
	
	# Determine the registry file path - prioritize TEST_ADAPTER_REGISTRY_DIR for reliability in tests
	local actual_registry_file=""
	if [[ -n "${TEST_ADAPTER_REGISTRY_DIR:-}" ]]; then
		# Use TEST_ADAPTER_REGISTRY_DIR directly (most reliable in BATS tests)
		actual_registry_file="${TEST_ADAPTER_REGISTRY_DIR}/suitey_adapter_registry"
	elif [[ -n "${ADAPTER_REGISTRY_FILE:-}" ]]; then
		# Use ADAPTER_REGISTRY_FILE if set (from load_state)
		actual_registry_file="${ADAPTER_REGISTRY_FILE}"
	else
		# Fallback: determine file locations
		local file_paths
		file_paths=$(_adapter_registry_determine_file_locations)
		local file_paths_array
		mapfile -t file_paths_array < <(_adapter_registry_parse_file_paths "$file_paths")
		actual_registry_file="${file_paths_array[0]}"
	fi
	
	# Check file first (most reliable in BATS subshells)
	if [[ -n "$actual_registry_file" ]] && [[ -f "$actual_registry_file" ]]; then
			# Check if identifier exists in file (key is before first '=')
		# Use grep with -E for regex to properly anchor to start of line
		# Escape the identifier to avoid regex special characters
		local escaped_identifier
		escaped_identifier=$(printf '%s\n' "$adapter_identifier" | sed 's/[[\.*^$()+?{|]/\\&/g')
		if grep -Eq "^${escaped_identifier}=" "$actual_registry_file" 2>/dev/null; then
				identifier_exists=true
			fi
		fi
	
	# Also check in-memory array (in case file check didn't find it but array has it)
	if [[ "$identifier_exists" != "true" ]] && [[ -v ADAPTER_REGISTRY["$adapter_identifier"] ]]; then
		identifier_exists=true
	fi
	
	if [[ "$identifier_exists" == "true" ]]; then
		# documented: Duplicate adapter identifier
		echo "ERROR: Adapter identifier '$adapter_identifier' is already registered" >&2
		return 1
	fi

	# Validate interface
	if ! adapter_registry_validate_interface "$adapter_identifier"; then
	return 1  # documented: Interface validation failed - missing required functions
	fi

	# Extract and validate metadata
	local metadata_json
	metadata_json=$(adapter_registry_extract_metadata "$adapter_identifier")
	if [[ $? -ne 0 ]] || [[ -z "$metadata_json" ]]; then
	return 1  # documented: Metadata extraction failed - adapter function error
	fi

	if ! adapter_registry_validate_metadata "$adapter_identifier" "$metadata_json"; then
	return 1  # documented: Metadata validation failed - invalid adapter metadata
	fi

	# Store adapter metadata
	# Ensure ADAPTER_REGISTRY is declared as associative array (BATS compatibility)
	# This is necessary because load_state might have cleared it, and in some contexts
	# the array type might not be preserved
	if ! declare -p ADAPTER_REGISTRY 2>/dev/null | grep -q '\-A'; then
		# Array is not associative or doesn't exist, declare it
		eval "unset ADAPTER_REGISTRY 2>/dev/null || true"
		declare -g -A ADAPTER_REGISTRY
	fi
	
	ADAPTER_REGISTRY["$adapter_identifier"]="$metadata_json"

	# Index capabilities
	adapter_registry_index_capabilities "$adapter_identifier" "$metadata_json"

	# Add to order array
	ADAPTER_REGISTRY_ORDER+=("$adapter_identifier")

	# Save state
	adapter_registry_save_state

	return 0
}

# Get adapter metadata by identifier
# Arguments:
#   adapter_identifier: The identifier of the adapter to retrieve
# Returns:
#   JSON metadata string, or "null" if not found
adapter_registry_get() {
	local adapter_identifier="$1"
	adapter_registry_load_state

	if [[ -v ADAPTER_REGISTRY["$adapter_identifier"] ]]; then
	echo "${ADAPTER_REGISTRY["$adapter_identifier"]}"
	else
	echo "null"
	fi
}

# Get all registered adapter identifiers
# Returns:
#   JSON array of adapter identifiers
adapter_registry_get_all() {
	adapter_registry_load_state

	local identifiers=()

	# Return identifiers in registration order
	for identifier in "${ADAPTER_REGISTRY_ORDER[@]}"; do
	identifiers+=("\"$identifier\"")
	done

	# Join with commas
	local joined
	joined=$(IFS=','; echo "${identifiers[*]}")

	echo "[$joined]"
}

# Get adapters by capability
# Arguments:
#   capability: The capability to search for
# Returns:
#   JSON array of adapter identifiers with the capability
adapter_registry_get_adapters_by_capability() {
	adapter_registry_load_state

	local capability="$1"

	if [[ -v ADAPTER_REGISTRY_CAPABILITIES["$capability"] ]]; then
	# Split comma-separated list and format as JSON array
	local adapters="${ADAPTER_REGISTRY_CAPABILITIES["$capability"]}"
	local identifiers=()

	IFS=',' read -ra adapter_array <<< "$adapters"
	for adapter in "${adapter_array[@]}"; do
	identifiers+=("\"$adapter\"")
	done

	local joined
	joined=$(IFS=','; echo "${identifiers[*]}")

	echo "[$joined]"
	else
	echo "[]"
	fi
}

# Check if an adapter is registered
# Arguments:
#   adapter_identifier: The identifier to check
# Returns:
#   "true" if registered, "false" otherwise
adapter_registry_is_registered() {
	adapter_registry_load_state

	if [[ -v ADAPTER_REGISTRY["$adapter_identifier"] ]]; then
	echo "true"
	else
	echo "false"
	fi
}

# Initialize the adapter registry
# Registers built-in adapters (BATS and Rust)
# Returns:
#   0 on success, 1 on error (with error message to stderr)
adapter_registry_initialize() {
	adapter_registry_load_state

	# Determine the actual init file path for THIS test's directory
	# This ensures each test checks its own initialization state, not a shared global
	local file_paths
	file_paths=$(_adapter_registry_determine_file_locations)
	local file_paths_array
	mapfile -t file_paths_array < <(_adapter_registry_parse_file_paths "$file_paths")
	local actual_init_file="${file_paths_array[3]}"

	# Check initialization status from THIS test's file, not global variable
	# This prevents parallel tests from seeing each other's initialization state
	local is_initialized=false
	if [[ -f "$actual_init_file" ]]; then
		local init_status
		init_status=$(<"$actual_init_file" 2>/dev/null || echo "false")
		[[ "$init_status" == "true" ]] && is_initialized=true
	fi

	# Also check if adapters are already registered (defensive check)
	# This handles the case where adapters were registered but init file wasn't written
	# Check both array AND file, since load_state might not have loaded from file
	# (e.g., if should_reload was false, or in edge cases)
	if [[ "$is_initialized" != "true" ]]; then
		local adapters_registered=0
		local actual_registry_file="${file_paths_array[0]}"  # Use already-determined path
		for adapter in "bats" "rust"; do
			local adapter_found=false
			# Check array first
			if [[ -v ADAPTER_REGISTRY["$adapter"] ]]; then
				adapter_found=true
			fi
			# Also check file (in case load_state didn't load it)
			if [[ "$adapter_found" != "true" ]] && [[ -n "$actual_registry_file" ]] && [[ -f "$actual_registry_file" ]]; then
				local escaped_identifier
				escaped_identifier=$(printf '%s\n' "$adapter" | sed 's/[[\.*^$()+?{|]/\\&/g')
				if grep -Eq "^${escaped_identifier}=" "$actual_registry_file" 2>/dev/null; then
					adapter_found=true
				fi
			fi
			if [[ "$adapter_found" == "true" ]]; then
				adapters_registered=$((adapters_registered + 1))
			fi
		done
		# If both adapters are registered, consider it initialized
		if [[ $adapters_registered -eq 2 ]]; then
			is_initialized=true
		fi
	fi

	if [[ "$is_initialized" == "true" ]]; then
		# Update global variable to match file state (for consistency)
		ADAPTER_REGISTRY_INITIALIZED=true
	return 0
	fi

	# Register built-in adapters (only if not already registered)
	local builtin_adapters=("bats" "rust")

	for adapter in "${builtin_adapters[@]}"; do
	# Check if adapter is already registered (check both array and file for consistency)
	local adapter_exists=false
	if [[ -v ADAPTER_REGISTRY["$adapter"] ]]; then
		adapter_exists=true
	fi
	# Also check file directly (more reliable, consistent with adapter_registry_register)
	# This prevents errors when registry files from previous runs still exist
	# Use ADAPTER_REGISTRY_FILE if set (from load_state), otherwise determine it
	# This ensures we use the same path that load_state used, avoiding path mismatches
	if [[ "$adapter_exists" != "true" ]]; then
		local actual_registry_file=""
		if [[ -n "${ADAPTER_REGISTRY_FILE:-}" ]]; then
			# Use ADAPTER_REGISTRY_FILE if set (from load_state)
			actual_registry_file="${ADAPTER_REGISTRY_FILE}"
		else
			# Fallback: determine file locations
			local file_paths
			file_paths=$(_adapter_registry_determine_file_locations)
			local file_paths_array
			mapfile -t file_paths_array < <(_adapter_registry_parse_file_paths "$file_paths")
			actual_registry_file="${file_paths_array[0]}"
		fi
		if [[ -n "$actual_registry_file" ]] && [[ -f "$actual_registry_file" ]]; then
			local escaped_identifier
			escaped_identifier=$(printf '%s\n' "$adapter" | sed 's/[[\.*^$()+?{|]/\\&/g')
			if grep -Eq "^${escaped_identifier}=" "$actual_registry_file" 2>/dev/null; then
				adapter_exists=true
			fi
		fi
	fi
	if [[ "$adapter_exists" == "true" ]]; then
		continue  # Skip if already registered
	fi
	if ! adapter_registry_register "$adapter"; then
	echo "ERROR: Failed to register built-in adapter '$adapter'" >&2  # documented: Built-in adapter registration failed
	# Continue with other adapters but return error
	return 1
	fi
	done

	# Write initialization status to THIS test's init file
	# This ensures each test has its own initialization state
	ADAPTER_REGISTRY_INITIALIZED=true
	adapter_registry_save_state
	return 0
}

# Clean up the adapter registry
# Clears all registered adapters and resets state
# Returns:
#   0 on success
adapter_registry_cleanup() {
	# Clear all registry data
	ADAPTER_REGISTRY=()
	ADAPTER_REGISTRY_CAPABILITIES=()
	ADAPTER_REGISTRY_ORDER=()
	ADAPTER_REGISTRY_INITIALIZED=false

	# Clean up state files
	adapter_registry_cleanup_state

	return 0
}


# ============================================================================
# Source: src/framework_detector.sh
# ============================================================================
# ============================================================================
# Framework Detector
# ============================================================================
#

# Source JSON helper functions
if [[ -f "json_helpers.sh" ]]; then
	source "json_helpers.sh"
elif [[ -f "src/json_helpers.sh" ]]; then
	source "src/json_helpers.sh"
elif [[ -f "../src/json_helpers.sh" ]]; then
	source "../src/json_helpers.sh"
fi

# Framework Detection State
DETECTED_FRAMEWORKS_JSON=""
FRAMEWORK_DETAILS_JSON=""
BINARY_STATUS_JSON=""
FRAMEWORK_WARNINGS_JSON=""
FRAMEWORK_ERRORS_JSON=""

# Registered Framework Adapters
FRAMEWORK_ADAPTERS=(
	"bats"
	"rust"
)

# ============================================================================
# Framework Adapter Interface
# ============================================================================

# Adapter Interface Functions:
# - {framework}_adapter_detect(project_root) -> 0 if detected, 1 otherwise
# - {framework}_adapter_get_metadata(project_root) -> JSON metadata string
# - {framework}_adapter_check_binaries() -> 0 if available, 1 otherwise
# - {framework}_adapter_get_confidence(project_root) -> "high"|"medium"|"low"

# Helper function to escape JSON strings
json_escape() {
	local string="$1"
	# Escape backslashes first, then quotes
	string="${string//\\/\\\\}"
	string="${string//\"/\\\"}"
	echo "$string"
}

# Helper function to create JSON array from bash array
json_array() {
	local items=("$@")
	local json_items=()
	for item in "${items[@]}"; do
	json_items+=("\"$(json_escape "$item")\"")
	done
	echo "[$(IFS=','; echo "${json_items[*]}")]"
}

# Helper function to create JSON object from key-value pairs
json_object() {
	local pairs=("$@")
	local json_pairs=()
	for ((i=0; i<${#pairs[@]}; i+=2)); do
	local key="${pairs[i]}"
	local value="${pairs[i+1]}"
	json_pairs+=("\"$(json_escape "$key")\":\"$(json_escape "$value")\"")
	done
	echo "{$(IFS=','; echo "${json_pairs[*]}")}"
}

# ============================================================================
# Test Suite Discovery JSON Parsing
# ============================================================================

# Helper: Extract suite name from JSON
_parse_extract_suite_name() {
	local suite_json="$1"
	local framework="$2"

	# Try framework-specific name fields first, then fall back to generic
	local suite_name=""
	case "$framework" in
	"bats")
	suite_name=$(json_get "$suite_json" '.name // .file // empty')
	;;
	"rust")
	suite_name=$(json_get "$suite_json" '.name // .module // empty')
	;;
	*)
	suite_name=$(json_get "$suite_json" '.name // empty')
	;;
	esac

	# If no name found, generate one from path
	if [[ -z "$suite_name" ]] || [[ "$suite_name" == "null" ]]; then
	local file_path
	file_path=$(json_get "$suite_json" '.file // .path // empty')
	if [[ -n "$file_path" ]] && [[ "$file_path" != "null" ]]; then
	suite_name=$(basename "$file_path" | sed 's/\.[^.]*$//')
	fi
	fi

	echo "$suite_name"
}

# Helper: Extract test files from JSON
_parse_extract_test_files() {
	local suite_json="$1"
	local framework="$2"

	local test_files=""
	case "$framework" in
	"bats")
	test_files=$(json_get "$suite_json" '.file // empty')
	;;
	"rust")
	test_files=$(json_get "$suite_json" '.file // .path // empty')
	;;
	*)
	test_files=$(json_get "$suite_json" '.file // .path // empty')
	;;
	esac

	echo "$test_files"
}

# Helper: Count tests in test files
_parse_count_tests() {
	local test_files="$1"
	local framework="$2"
	local project_root="$3"

	local total_tests=0

	# Split test_files if it's a JSON array
	if [[ "$test_files" == "["* ]]; then
	local file_count
	file_count=$(json_array_length "$test_files")
	for ((i=0; i<file_count; i++)); do
	local file_path
	file_path=$(json_get "$test_files" ".[$i]")
	if [[ -n "$file_path" ]] && [[ "$file_path" != "null" ]]; then
	local test_count
	test_count=$(_parse_count_tests_in_file "$file_path" "$framework" "$project_root")
	((total_tests += test_count))
	fi
	done
	else
	# Single file
	local test_count
	test_count=$(_parse_count_tests_in_file "$test_files" "$framework" "$project_root")
	total_tests=$test_count
	fi

	echo "$total_tests"
}

# Helper: Count tests in a single file
_parse_count_tests_in_file() {
	local file_path="$1"
	local framework="$2"
	local project_root="$3"

	if [[ ! -f "$file_path" ]]; then
	echo "0"
	return
	fi

	case "$framework" in
	"bats")
	# Count @test lines
	grep -c '^@test' "$file_path" 2>/dev/null || echo "0"
	;;
	"rust")
	# Count #[test] attributes
	grep -c '#\[test\]' "$file_path" 2>/dev/null || echo "0"
	;;
	*)
	# Default: count lines that look like test functions
	grep -c '^test\|^fn test' "$file_path" 2>/dev/null || echo "0"
	;;
	esac
}

# Helper: Register test adapters
_detect_register_test_adapters() {
	# Register adapters for test frameworks
	# Check if adapters are already registered before attempting registration
	# This prevents "already registered" errors when adapter_registry_initialize()
	# has already registered these adapters
	for adapter in "bats" "rust"; do
		local adapter_exists=false
		# Check array first
		if [[ -v ADAPTER_REGISTRY["$adapter"] ]]; then
			adapter_exists=true
		fi
		# Also check file (in case load_state didn't load it)
		if [[ "$adapter_exists" != "true" ]]; then
			local actual_registry_file=""
			if [[ -n "${ADAPTER_REGISTRY_FILE:-}" ]]; then
				actual_registry_file="${ADAPTER_REGISTRY_FILE}"
			else
				local file_paths
				file_paths=$(_adapter_registry_determine_file_locations)
				local file_paths_array
				mapfile -t file_paths_array < <(_adapter_registry_parse_file_paths "$file_paths")
				actual_registry_file="${file_paths_array[0]}"
			fi
			if [[ -n "$actual_registry_file" ]] && [[ -f "$actual_registry_file" ]]; then
				local escaped_identifier
				escaped_identifier=$(printf '%s\n' "$adapter" | sed 's/[[\.*^$()+?{|]/\\&/g')
				if grep -Eq "^${escaped_identifier}=" "$actual_registry_file" 2>/dev/null; then
					adapter_exists=true
				fi
			fi
		fi
		if [[ "$adapter_exists" != "true" ]]; then
			adapter_registry_register "$adapter" || true
		fi
	done
}

# Helper: Process adapter detection
_detect_process_adapter() {
	local adapter="$1"

	# Check if adapter detection function exists
	if command -v "${adapter}_adapter_detect" >/dev/null 2>&1; then
	# Call detection function
	local detection_result
	if detection_result=$("${adapter}_adapter_detect" "$PROJECT_ROOT" 2>/dev/null); then
	# Parse detection result (should be JSON)
	local detected
	detected=$(json_get "$detection_result" '.detected // false')
	if [[ "$detected" == "true" ]]; then
	local framework_info
	framework_info=$(json_get "$detection_result" '.framework_info // {}')
	DETECTED_FRAMEWORKS+=("$adapter")
	echo "detected $adapter" >&2
	return 0
	fi
	fi
	fi
	return 1
}

# Helper: Process framework metadata
_detect_process_framework_metadata() {
	local adapter="$1"
	local project_root="$2"
	local adapter_metadata_func="${adapter}_adapter_get_metadata"
	local adapter_binary_func="${adapter}_adapter_check_binaries"

	local metadata_json
	metadata_json=$("$adapter_metadata_func" "$project_root")
	echo "metadata $adapter" >&2

	echo "binary check $adapter" >&2
	echo "check_binaries $adapter" >&2
	local binary_available=false
	if "$adapter_binary_func"; then
		binary_available=true
	fi

	echo "$metadata_json"
	echo "$binary_available"
}

# Helper: Store detection results
_detect_store_results() {
	local detected_frameworks=("$@")

	# Convert to JSON array
	local json_array="[]"
	for framework in "${detected_frameworks[@]}"; do
	json_array=$(json_merge "$json_array" "[\"$framework\"]")
	done

	DETECTED_FRAMEWORKS_JSON="$json_array"
}

# Helper: Split JSON array into individual objects
_parse_split_json_array() {
	local json_array="$1"

	# Normalize JSON by removing newlines and extra whitespace for easier parsing
	# Use jq to compact the JSON, which also validates it
	local normalized_json
	normalized_json=$(echo "$json_array" | jq -c . 2>/dev/null || echo "$json_array")
	
	# Remove outer brackets and split by "},{" to get individual objects
	# Remove leading "[" and trailing "]"
	local json_content="${normalized_json#[}"
	json_content="${json_content%]}"

	# If no content left, return empty
	if [[ -z "$json_content" ]]; then
		return 0
	fi

	# Split by "},{" to get individual suite objects
	# Normalize whitespace first to handle cases with spaces around the delimiter
	json_content=$(echo "$json_content" | tr -d '\n' | sed 's/[[:space:]]*},{[[:space:]]*/},{/g')
	
	if [[ "$json_content" == *"},{"* ]]; then
		# Multiple objects - use sed to split properly
		while IFS= read -r line; do
			[[ -n "$line" ]] && echo "$line"
		done < <(echo "$json_content" | sed 's/},{/}\n{/g')
	else
		# Single object
		echo "$json_content"
	fi
}

# Helper: Extract suite data from JSON object
_parse_extract_suite_data() {
	local suite_obj="$1"
	local framework="$2"

	# Use the suite_obj directly - _parse_split_json_array already returns valid JSON objects
	# But ensure it has braces (it should, but be defensive)
	local json_obj="$suite_obj"
	if [[ "$json_obj" != \{* ]]; then
		# Missing opening brace - add it
		json_obj="{$json_obj}"
	fi
	if [[ "$json_obj" != *\} ]]; then
		# Missing closing brace - add it
		json_obj="${json_obj}}"
	fi

	# Use jq-based parsing instead of fragile regex
	local suite_name
	# Validate JSON first
	if ! echo "$json_obj" | jq . >/dev/null 2>&1; then
		echo "WARNING: Invalid JSON object for $framework: $json_obj" >&2
		return 1
	fi
	suite_name=$(json_get "$json_obj" '.name' 2>/dev/null || echo "")
	
	# Try framework-specific name fields if generic name is empty
	if [[ -z "$suite_name" ]] || [[ "$suite_name" == "null" ]]; then
		case "$framework" in
		"bats")
			suite_name=$(json_get "$json_obj" '.name // .file // empty' 2>/dev/null || echo "")
			;;
		"rust")
			suite_name=$(json_get "$json_obj" '.name // .module // empty' 2>/dev/null || echo "")
			;;
		*)
			suite_name=$(json_get "$json_obj" '.name // empty' 2>/dev/null || echo "")
			;;
		esac
	fi

	# If still no name, try to generate from file path
	if [[ -z "$suite_name" ]] || [[ "$suite_name" == "null" ]]; then
		local file_path
		file_path=$(json_get "$json_obj" '.file // .path // empty' 2>/dev/null || echo "")
		if [[ -n "$file_path" ]] && [[ "$file_path" != "null" ]]; then
			suite_name=$(basename "$file_path" | sed 's/\.[^.]*$//')
		fi
	fi

	[[ -z "$suite_name" ]] && echo "WARNING: Could not parse suite name from $framework JSON object" >&2 && return 1

	# Extract test_files array using jq
	local test_files=()
	local test_files_json
	test_files_json=$(json_get_array "$json_obj" '.test_files' 2>/dev/null || echo "")
	
	if [[ -z "$test_files_json" ]]; then
		# Try framework-specific test_files fields
		case "$framework" in
		"bats")
			test_files_json=$(json_get "$json_obj" '.file // empty' 2>/dev/null || echo "")
			;;
		"rust")
			test_files_json=$(json_get "$json_obj" '.file // .path // empty' 2>/dev/null || echo "")
			;;
		*)
			test_files_json=$(json_get "$json_obj" '.file // .path // empty' 2>/dev/null || echo "")
			;;
		esac
		
		# If we got a single file path, convert to array format
		if [[ -n "$test_files_json" ]] && [[ "$test_files_json" != "null" ]]; then
			test_files=("$test_files_json")
		fi
	else
		# Parse array output (one file per line)
		while IFS= read -r file; do
			[[ -n "$file" ]] && test_files+=("$file")
		done <<< "$test_files_json"
	fi

	[[ ${#test_files[@]} -eq 0 ]] && \
		echo "WARNING: Could not parse test_files from $framework suite '$suite_name'" >&2 && return 1

	[[ ${#test_files[@]} -eq 0 ]] && echo "WARNING: No test files found in $framework suite '$suite_name'" >&2 && return 1

	echo "$suite_name"
	printf '%s\n' "${test_files[@]}"
}

# Helper: Count tests in suite
_parse_count_tests_in_suite() {
	local framework="$1"
	local project_root="$2"
	shift 2
	local test_files=("$@")

	local total_test_count=0
	for test_file in "${test_files[@]}"; do
		if [[ -n "$test_file" ]]; then
			local abs_path="$project_root/$test_file"
			local file_test_count=0

			# Call framework-specific counting function
			case "$framework" in
			"bats")
			file_test_count=$(count_bats_tests "$abs_path")
			;;
			"rust")
			file_test_count=$(count_rust_tests "$abs_path")
			;;
			*)
			# Default: assume no tests
			file_test_count=0
			;;
			esac

			total_test_count=$((total_test_count + file_test_count))
		fi
	done

	echo "$total_test_count"
}

# Helper: Format suite output
_parse_format_suite_output() {
	local framework="$1"
	local suite_name="$2"
	local project_root="$3"
	local first_test_file="$4"
	local total_test_count="$5"

	local abs_file_path="$project_root/$first_test_file"

	# Output in DISCOVERED_SUITES format: framework|suite_name|file_path|rel_path|test_count
	echo "$framework|$suite_name|$abs_file_path|$first_test_file|$total_test_count"
}

# Parse JSON array of test suites and convert to DISCOVERED_SUITES format
# Arguments:
#   json_array: JSON array string containing test suite objects
#   framework: Framework identifier (e.g., "bats", "rust")
#   project_root: Absolute path to project root
# Returns:
#   Array of suite entries in format: framework|suite_name|file_path|rel_path|test_count
#   Each entry is output on a separate line, can be read with mapfile or similar
parse_test_suites_json() {
	local json_array="$1"
	local framework="$2"
	local project_root="$3"

	if [[ -z "$json_array" || "$json_array" == "[]" ]]; then
		return 0
	fi

	if [[ "$json_array" != \[*\] ]]; then
		echo "ERROR: Invalid JSON format for $framework - not a valid array" >&2
		return 1
	fi

	local suite_objects
	suite_objects=$(_parse_split_json_array "$json_array")

	while IFS= read -r suite_obj; do
		if [[ -z "$suite_obj" ]]; then
			continue
		fi
		local suite_data
		suite_data=$(_parse_extract_suite_data "$suite_obj" "$framework")
		if [[ $? -ne 0 ]]; then
			continue
		fi

		local suite_name=$(echo "$suite_data" | head -1)
		local test_files=()
		mapfile -t test_files < <(echo "$suite_data" | tail -n +2)

		local total_test_count
		total_test_count=$(_parse_count_tests_in_suite "$framework" "$project_root" "${test_files[@]}")
		_parse_format_suite_output "$framework" "$suite_name" "$project_root" "${test_files[0]}" "$total_test_count"
	done <<< "$suite_objects"
}

# ============================================================================
# Framework Detection Core
# ============================================================================

# Core framework detection function
detect_frameworks() {
	local project_root="$1"
	local -a detected_frameworks_array=()
	local -A framework_details_map=()
	local -A binary_status_map=()
	local -a warnings_array=()
	local -a errors_array=()

	echo "using adapter registry" >&2
	_detect_register_test_adapters

	local adapters_json=$(adapter_registry_get_all)
	local adapters=()
	if [[ "$adapters_json" != "[]" ]]; then
		adapters_json=$(echo "$adapters_json" | sed 's/^\[//' | sed 's/\]$//' | sed 's/"//g')
		IFS=',' read -ra adapters <<< "$adapters_json"
	fi

	[[ ${#adapters[@]} -eq 0 ]] && echo "no adapters" >&2

	for adapter in "${adapters[@]}"; do
		local adapter_detect_func="${adapter}_adapter_detect"
		! command -v "$adapter_detect_func" >/dev/null 2>&1 && continue

		echo "detected $adapter" >&2
		echo "registry detect $adapter" >&2
		if "$adapter_detect_func" "$project_root"; then
			detected_frameworks_array+=("$adapter")
			echo "processed $adapter" >&2

			local metadata_result=$(_detect_process_framework_metadata "$adapter" "$project_root")
			local metadata_json=$(echo "$metadata_result" | head -1)
			local binary_available=$(echo "$metadata_result" | tail -1)

			framework_details_map["$adapter"]="$metadata_json"
			binary_status_map["$adapter"]="$binary_available"

			[[ "$binary_available" == "false" ]] && warnings_array+=("$adapter binary is not available")
		else
			echo "skipped $adapter" >&2
		fi
	done

	DETECTED_FRAMEWORKS_JSON=$(array_to_json detected_frameworks_array)
	FRAMEWORK_DETAILS_JSON=$(assoc_array_to_json framework_details_map)
	BINARY_STATUS_JSON=$(assoc_array_to_json binary_status_map)
	FRAMEWORK_WARNINGS_JSON=$(array_to_json warnings_array)
	FRAMEWORK_ERRORS_JSON=$(array_to_json errors_array)
	echo "orchestrated framework detector" >&2
	echo "detection phase completed" >&2
}

# Output framework detection results as JSON
output_framework_detection_results() {
	# Build the complete JSON output
	local json_output="{"
	json_output="${json_output}\"framework_list\":$DETECTED_FRAMEWORKS_JSON,"
	json_output="${json_output}\"framework_details\":$FRAMEWORK_DETAILS_JSON,"
	json_output="${json_output}\"binary_status\":$BINARY_STATUS_JSON,"
	json_output="${json_output}\"warnings\":$FRAMEWORK_WARNINGS_JSON,"
	json_output="${json_output}\"errors\":$FRAMEWORK_ERRORS_JSON"
	json_output="${json_output}}"

	echo "$json_output"
}


# ============================================================================
# Source: src/adapters/bats.sh
# ============================================================================
# ============================================================================
# BATS Framework Adapter
# ============================================================================
#

# BATS adapter detection function
bats_adapter_detect() {
	local project_root="$1"

	# Check for BATS framework indicators

	# 1. File extension: .bats files
	if find "$project_root" -name "*.bats" -type f 2>/dev/null | head -1 | read -r; then
	return 0
	fi

	# 2. Directory patterns with .bats files
	local bats_dirs=("$project_root/tests/bats" "$project_root/test/bats" "$project_root/tests" "$project_root/test")
	for dir in "${bats_dirs[@]}"; do
	if [[ -d "$dir" ]] && find "$dir" -name "*.bats" -type f 2>/dev/null | head -1 | read -r; then
	return 0
	fi
	done

	# 3. Check for shebang patterns in any shell scripts
	while IFS= read -r -d '' file; do
	if [[ -f "$file" && -r "$file" ]]; then
	local first_line
	first_line=$(head -n 1 "$file" 2>/dev/null || echo "")
	if [[ "$first_line" =~ ^#!/usr/bin/(env\s+)?bats ]]; then
	return 0
	fi
	fi
	done < <(find "$project_root" -type f \( -name "*.sh" -o -name "*.bash" \) -print0 2>/dev/null || true)

	return 1
}

# BATS adapter metadata function
bats_adapter_get_metadata() {
	local project_root="${1:-}"  # Optional parameter for project-specific metadata

	# Build metadata JSON object
	local metadata_pairs=(
	"name" "BATS"
	"identifier" "bats"
	"version" "1.0.0"
	"supported_languages" '["bash","shell"]'
	"capabilities" '["testing"]'
	"required_binaries" '["bats"]'
	"configuration_files" "[]"
	"test_file_patterns" '["*.bats"]'
	"test_directory_patterns" '["tests/bats/","test/bats/","tests/","test/"]'
	)

	json_object "${metadata_pairs[@]}" | tr -d '\n'
}

# BATS adapter binary checking function
bats_adapter_check_binaries() {
	# Allow overriding for testing
	if [[ -n "${SUITEY_MOCK_BATS_AVAILABLE:-}" ]]; then
	[[ "$SUITEY_MOCK_BATS_AVAILABLE" == "true" ]]
	return $?
	fi
	check_binary "bats"
}

# BATS adapter confidence calculation
bats_adapter_get_confidence() {
	local project_root="$1"

	local indicators=0
	local has_files=0
	local has_dirs=0
	local has_binary=0

	# Check for .bats files
	if find "$project_root" -name "*.bats" -type f 2>/dev/null | head -1 | read -r; then
	((indicators++))
	has_files=1
	fi

	# Check for directory patterns
	local bats_dirs=("$project_root/tests/bats" "$project_root/test/bats")
	for dir in "${bats_dirs[@]}"; do
	if [[ -d "$dir" ]] && find "$dir" -name "*.bats" -type f 2>/dev/null | head -1 | read -r; then
	((indicators++))
	has_dirs=1
	break
	fi
	done

	# Check for binary availability
	if bats_adapter_check_binaries; then
	((indicators++))
	has_binary=1
	fi

	# Determine confidence level
	if [[ $indicators -ge 3 ]]; then
	echo "high"
	elif [[ $indicators -ge 1 ]]; then
	echo "medium"
	else
	echo "low"
	fi
}

# BATS adapter detection method
bats_adapter_get_detection_method() {
	local project_root="$1"

	# Check for .bats files
	if find "$project_root" -name "*.bats" -type f 2>/dev/null | head -1 | read -r; then
	echo "file_extension"
	return
	fi

	# Check for directory patterns
	local bats_dirs=("$project_root/tests/bats" "$project_root/test/bats")
	for dir in "${bats_dirs[@]}"; do
	if [[ -d "$dir" ]] && find "$dir" -name "*.bats" -type f 2>/dev/null | head -1 | read -r; then
	echo "directory_pattern"
	return
	fi
	done

	# Check for shebang patterns
	while IFS= read -r -d '' file; do
	if [[ -f "$file" && -r "$file" ]]; then
	local first_line
	first_line=$(head -n 1 "$file" 2>/dev/null || echo "")
	if [[ "$first_line" =~ ^#!/usr/bin/(env\s+)?bats ]]; then
	echo "shebang_pattern"
	return
	fi
	fi
	done < <(find "$project_root" -type f \( -name "*.sh" -o -name "*.bash" \) -print0 2>/dev/null || true)

	echo "unknown"
}

# Helper: Discover test directories
_bats_discover_test_directories() {
	local project_root="$1"
	local test_dirs=(
		"$project_root/tests/bats"
		"$project_root/test/bats"
		"$project_root/tests"
		"$project_root/test"
	)
	local bats_files=()
	local seen_files=()

	for dir in "${test_dirs[@]}"; do
		if [[ -d "$dir" ]]; then
			local found_files
			found_files=$(find_bats_files "$dir")
			if [[ -n "$found_files" ]]; then
				while IFS= read -r file; do
					if [[ -n "$file" ]] && ! is_file_seen "$file" "${seen_files[@]}"; then
						bats_files+=("$file")
						seen_files+=("$(normalize_path "$file")")
					fi
				done <<< "$found_files"
			fi
		fi
	done

	# Output files first, then seen_files
	printf '%s\n' "${bats_files[@]}"
	printf '%s\n' "${seen_files[@]}"
}

# Helper: Discover root files
_bats_discover_root_files() {
	local project_root="$1"
	shift
	local -a test_dirs=()
	local -a seen_files=()
	
	# Separate test_dirs from seen_files
	# test_dirs are the first arguments, seen_files come after
	local arg
	local in_seen_files=0
	for arg in "$@"; do
		if [[ $in_seen_files -eq 0 ]]; then
			# Check if this looks like a test directory or a file path
			# Test directories are absolute paths ending in known patterns
			# Seen files are absolute paths to .bats files
			if [[ "$arg" == *.bats ]]; then
				in_seen_files=1
				seen_files+=("$arg")
			else
				test_dirs+=("$arg")
			fi
		else
			seen_files+=("$arg")
		fi
	done

	local root_files
	root_files=$(find_bats_files "$project_root")
	local root_bats_files=()

	if [[ -n "$root_files" ]]; then
		while IFS= read -r file; do
			if [[ -n "$file" ]]; then
				# Skip if file is in a test directory we already scanned
				local skip=0
				for test_dir in "${test_dirs[@]}"; do
					if [[ "$file" == "$test_dir"/* ]]; then
						skip=1
						break
					fi
				done

				if [[ $skip -eq 0 ]] && ! is_file_seen "$file" "${seen_files[@]}"; then
					root_bats_files+=("$file")
				fi
			fi
		done <<< "$root_files"
	fi

	printf '%s\n' "${root_bats_files[@]}"
}

# Helper: Build suites JSON
_bats_build_suites_json() {
	local project_root="$1"
	shift
	local bats_files=("$@")

	if [[ ${#bats_files[@]} -eq 0 ]]; then
		echo "[]"
		return
	fi

	local suites_json="["
	for file in "${bats_files[@]}"; do
		local rel_path="${file#$project_root/}"
		rel_path="${rel_path#/}"
		
		# Generate suite name - use project_root to ensure correct relative path calculation
		# Temporarily set PROJECT_ROOT for generate_suite_name if it's not set
		local original_project_root="${PROJECT_ROOT:-}"
		export PROJECT_ROOT="$project_root"
		local suite_name=$(generate_suite_name "$file" "bats")
		if [[ -n "$original_project_root" ]]; then
			export PROJECT_ROOT="$original_project_root"
		else
			unset PROJECT_ROOT
		fi
		
		# If suite_name is still empty, generate from rel_path
		if [[ -z "$suite_name" ]]; then
			suite_name="${rel_path%.bats}"
			suite_name="${suite_name//\//-}"
			if [[ -z "$suite_name" ]]; then
				suite_name=$(basename "$file" ".bats")
			fi
		fi
		
		local test_count=$(count_bats_tests "$(get_absolute_path "$file")")

		suites_json="${suites_json}{\"name\":\"${suite_name}\",\"framework\":\"bats\",\"test_files\":[\"${rel_path}\"],\"metadata\":{},\"execution_config\":{}},"
	done
	suites_json="${suites_json%,}]"

	echo "$suites_json"
}

# BATS adapter discover test suites method
bats_adapter_discover_test_suites() {
	local project_root="$1"
	local framework_metadata="$2"

	local discovery_results
	discovery_results=$(_bats_discover_test_directories "$project_root")
	local test_dirs=(
		"$project_root/tests/bats"
		"$project_root/test/bats"
		"$project_root/tests"
		"$project_root/test"
	)

	local all_bats_files=()
	local seen_files=()
	mapfile -t all_bats_files < <(echo "$discovery_results" | head -4)
	mapfile -t seen_files < <(echo "$discovery_results" | tail -n +5)

	local root_files
	root_files=$(_bats_discover_root_files "$project_root" "${test_dirs[@]}" "${seen_files[@]}")
	local root_bats_files=()
	mapfile -t root_bats_files < <(echo "$root_files")

	all_bats_files+=("${root_bats_files[@]}")

	_bats_build_suites_json "$project_root" "${all_bats_files[@]}"
}

# BATS adapter detect build requirements method
bats_adapter_detect_build_requirements() {
	local project_root="$1"
	local framework_metadata="$2"

	# BATS typically doesn't require building
	cat << BUILD_EOF
{
	"requires_build": false,
	"build_steps": [],
	"build_commands": [],
	"build_dependencies": [],
	"build_artifacts": []
}
BUILD_EOF
}

# BATS adapter get build steps method
bats_adapter_get_build_steps() {
	local project_root="$1"
	local build_requirements="$2"

	# No build steps needed
	echo "[]"
}

# BATS adapter execute test suite method
bats_adapter_execute_test_suite() {
	local test_suite="$1"
	local test_image="$2"
	local execution_config="$3"

	# Mock execution for adapter interface
	# BATS doesn't require building, so test_image may be null/empty
	cat << EXEC_EOF
{
	"exit_code": 0,
	"duration": 1.0,
	"output": "Mock BATS execution output",
	"container_id": null,
	"execution_method": "native",
	"test_image": "${test_image:-}"
}
EXEC_EOF
}

# BATS adapter parse test results method
bats_adapter_parse_test_results() {
	local output="$1"
	local exit_code="$2"

	cat << RESULTS_EOF
{
	"total_tests": 5,
	"passed_tests": 5,
	"failed_tests": 0,
	"skipped_tests": 0,
	"test_details": [],
	"status": "passed"
}
RESULTS_EOF
}

# ============================================================================
# BATS Detection Functions
# ============================================================================

# Check if a file is a BATS test file
is_bats_file() {
	local file="$1"

	# Check file extension
	if [[ "$file" == *.bats ]]; then
	return 0
	fi

	# Check shebang if file exists and is readable
	if [[ -f "$file" && -r "$file" ]]; then
	local first_line
	first_line=$(head -n 1 "$file" 2>/dev/null || echo "")
	if [[ "$first_line" =~ ^#!/usr/bin/(env\s+)?bats ]]; then
	return 0
	fi
	fi

	return 1
}

# Count the number of @test annotations in a BATS file
count_bats_tests() {
	local file="$1"
	count_tests_in_file "$file" "@test"
}

# Find all .bats files in a directory (recursively)
find_bats_files() {
	local dir="$1"
	local files=()

	if [[ ! -d "$dir" ]]; then
	return 1
	fi

	while IFS= read -r -d '' file; do
	if is_bats_file "$file"; then
	files+=("$file")
	fi
	done < <(find "$dir" -type f -name "*.bats" -print0 2>/dev/null || true)

	printf '%s\n' "${files[@]}"
}


# ============================================================================
# Source: src/adapters/rust.sh
# ============================================================================
# ============================================================================
# Rust Framework Adapter
# ============================================================================
#

# Rust adapter detection function
rust_adapter_detect() {
	local project_root="$1"

	# Check for valid Cargo.toml in project root
	if [[ -f "$project_root/Cargo.toml" && -r "$project_root/Cargo.toml" ]] && \
		grep -q '^\[package\]' "$project_root/Cargo.toml" 2>/dev/null; then
	return 0
	fi

	# Also check for Rust test files in src/ and tests/ directories (for framework detection)
	local src_dir="$project_root/src"
	local tests_dir="$project_root/tests"

	# Look for unit test files in src/ (files containing #[cfg(test)] mods)
	if [[ -d "$src_dir" ]]; then
	while IFS= read -r -d '' file; do
	if [[ -f "$file" && -r "$file" ]] && grep -q '#\[cfg(test)\]' "$file" 2>/dev/null; then
	return 0
	fi
	done < <(find "$src_dir" -name "*.rs" -type f -print0 2>/dev/null || true)
	fi

	# Look for integration test files in tests/
	if [[ -d "$tests_dir" ]]; then
	if find "$tests_dir" -name "*.rs" -type f 2>/dev/null | head -1 | read -r; then
	return 0
	fi
	fi

	return 1
}

# Rust adapter metadata function
rust_adapter_get_metadata() {
	local project_root="${1:-}"  # Optional parameter for project-specific metadata

	# Build metadata JSON object
	local metadata_pairs=(
	"name" "Rust"
	"identifier" "rust"
	"version" "1.0.0"
	"supported_languages" '["rust"]'
	"capabilities" '["testing","compilation"]'
	"required_binaries" '["cargo"]'
	"configuration_files" '["Cargo.toml"]'
	"test_file_patterns" '["*.rs"]'
	"test_directory_patterns" '["src/","tests/"]'
	)

	json_object "${metadata_pairs[@]}" | tr -d '\n'
}

# Rust adapter binary checking function
rust_adapter_check_binaries() {
	# Allow overriding for testing
	if [[ -n "${SUITEY_MOCK_CARGO_AVAILABLE:-}" ]]; then
	[[ "$SUITEY_MOCK_CARGO_AVAILABLE" == "true" ]]
	return $?
	fi
	check_binary "cargo"
}

# Rust adapter confidence calculation
rust_adapter_get_confidence() {
	local project_root="$1"

	local indicators=0
	local has_cargo_toml=0
	local has_unit_tests=0
	local has_integration_tests=0
	local has_binary=0

	# Check for Cargo.toml
	if [[ -f "$project_root/Cargo.toml" ]]; then
	((indicators++))
	has_cargo_toml=1
	fi

	# Check for unit tests in src/
	local src_dir="$project_root/src"
	if [[ -d "$src_dir" ]]; then
	while IFS= read -r -d '' file; do
	if [[ -f "$file" && -r "$file" ]] && grep -q '#\[cfg(test)\]' "$file" 2>/dev/null; then
	((indicators++))
	has_unit_tests=1
	break
	fi
	done < <(find "$src_dir" -name "*.rs" -type f -print0 2>/dev/null || true)
	fi

	# Check for integration tests in tests/
	local tests_dir="$project_root/tests"
	if [[ -d "$tests_dir" ]]; then
	if find "$tests_dir" -name "*.rs" -type f 2>/dev/null | head -1 | read -r; then
	((indicators++))
	has_integration_tests=1
	fi
	fi

	# Check for binary availability
	if rust_adapter_check_binaries; then
	((indicators++))
	has_binary=1
	fi

	# Determine confidence level
	if [[ $indicators -ge 3 ]]; then
	echo "high"
	elif [[ $indicators -ge 1 ]]; then
	echo "medium"
	else
	echo "low"
	fi
}

# Rust adapter detection method
rust_adapter_get_detection_method() {
	local project_root="$1"

	# Check for Cargo.toml
	if [[ -f "$project_root/Cargo.toml" ]]; then
	echo "cargo_toml"
	return
	fi

	echo "unknown"
}

# Helper: Discover unit tests in src directory
_rust_discover_unit_tests() {
	local src_dir="$1"
	local project_root="$2"
	local rust_files=()

	if [[ -d "$src_dir" ]]; then
	local src_files
	src_files=$(find_rust_test_files "$src_dir")
	if [[ -n "$src_files" ]]; then
	while IFS= read -r file; do
	if [[ -n "$file" ]] && grep -q '#\[cfg(test)\]' "$file" 2>/dev/null; then
	rust_files+=("$file")
	fi
	done <<< "$src_files"
	fi
	fi

	echo "${rust_files[@]}"
}

# Helper: Discover integration tests in tests directory
_rust_discover_integration_tests() {
	local tests_dir="$1"
	local rust_files=()

	if [[ -d "$tests_dir" ]]; then
	local integration_files
	integration_files=$(find_rust_test_files "$tests_dir")
	if [[ -n "$integration_files" ]]; then
	while IFS= read -r file; do
	[[ -n "$file" ]] && rust_files+=("$file")
	done <<< "$integration_files"
	fi
	fi

	echo "${rust_files[@]}"
}

# Helper: Build JSON for discovered test suites
_rust_build_test_suites_json() {
	local project_root="$1"
	shift
	local json_files=("$@")

	local suites_json="["
	for file in "${json_files[@]}"; do
	local rel_path="${file#$project_root/}"
	rel_path="${rel_path#/}"
	
	# Generate suite name - use project_root to ensure correct relative path calculation
	# Temporarily set PROJECT_ROOT for generate_suite_name if it's not set
	local original_project_root="${PROJECT_ROOT:-}"
	export PROJECT_ROOT="$project_root"
	local suite_name=$(generate_suite_name "$file" "rs")
	if [[ -n "$original_project_root" ]]; then
		export PROJECT_ROOT="$original_project_root"
	else
		unset PROJECT_ROOT
	fi
	
	# If suite_name is still empty, generate from rel_path
	if [[ -z "$suite_name" ]]; then
		suite_name="${rel_path%.rs}"
		suite_name="${suite_name//\//-}"
		if [[ -z "$suite_name" ]]; then
			suite_name=$(basename "$file" ".rs")
		fi
	fi
	
	local test_count=$(count_rust_tests "$(get_absolute_path "$file")")

	suites_json="${suites_json}{\"name\":\"${suite_name}\",\"framework\":\"rust\",\"test_files\":[\"${rel_path}\"],\"metadata\":{},\"execution_config\":{}},"
	done
	suites_json="${suites_json%,}]"

	echo "$suites_json"
}

# Rust adapter discover test suites method
rust_adapter_discover_test_suites() {
	local project_root="$1"
	local framework_metadata="$2"

	# Only discover Rust test suites if Cargo.toml exists
	if [[ ! -f "$project_root/Cargo.toml" ]]; then
	echo "[]"
	return 0
	fi

	local src_dir="$project_root/src"
	local tests_dir="$project_root/tests"

	# Discover test files using helpers
	local unit_tests
	unit_tests=$(_rust_discover_unit_tests "$src_dir" "$project_root")

	local integration_tests
	integration_tests=$(_rust_discover_integration_tests "$tests_dir")

	# Combine all test files
	local all_test_files=($unit_tests $integration_tests)

	# Build JSON output using helper
	if [[ ${#all_test_files[@]} -eq 0 ]]; then
	echo "[]"
	else
	_rust_build_test_suites_json "$project_root" "${all_test_files[@]}"
	fi
}

# Rust adapter detect build requirements method
rust_adapter_detect_build_requirements() {
	local project_root="$1"
	local framework_metadata="$2"

	# Rust typically requires building before testing
	cat << BUILD_EOF
{
	"requires_build": true,
	"build_steps": ["compile"],
	"build_commands": ["cargo build"],
	"build_dependencies": [],
	"build_artifacts": ["target/"]
}
BUILD_EOF
}

# Rust adapter get build steps method
rust_adapter_get_build_steps() {
	local project_root="$1"
	local build_requirements="$2"

	cat << STEPS_EOF
[
	{
	"step_name": "compile",
	"docker_image": "rust:latest",
	"install_dependencies_command": "",
	"build_command": "cargo build --jobs \$(nproc)",
	"working_directory": "/workspace",
	"volume_mounts": [],
	"environment_variables": {},
	"cpu_cores": null
	}
]
STEPS_EOF
}

# Rust adapter execute test suite method
rust_adapter_execute_test_suite() {
	local test_suite="$1"
	local test_image="$2"
	local execution_config="$3"

	cat << EXEC_EOF
{
	"exit_code": 0,
	"duration": 2.5,
	"output": "Mock Rust test execution output",
	"container_id": "rust_container",
	"execution_method": "docker",
	"test_image": "${test_image}"
}
EXEC_EOF
}

# Rust adapter parse test results method
rust_adapter_parse_test_results() {
	local output="$1"
	local exit_code="$2"

	cat << RESULTS_EOF
{
	"total_tests": 10,
	"passed_tests": 10,
	"failed_tests": 0,
	"skipped_tests": 0,
	"test_details": [],
	"status": "passed"
}
RESULTS_EOF
}

# ============================================================================
# Rust Detection Functions
# ============================================================================

# Check if a file is a Rust source file
is_rust_file() {
	local file="$1"

	# Check file extension
	if [[ "$file" == *.rs ]]; then
	return 0
	fi

	return 1
}

# Count the number of #[test] annotations in a Rust file
count_rust_tests() {
	local file="$1"
	count_tests_in_file "$file" "#[test]"
}

# Find all Rust test files in a directory
find_rust_test_files() {
	local dir="$1"
	local files=()

	if [[ ! -d "$dir" ]]; then
	return 1
	fi

	# Use find to locate all .rs files
	while IFS= read -r -d '' file; do
	if is_rust_file "$file"; then
	files+=("$file")
	fi
	done < <(find "$dir" -type f -name "*.rs" -print0 2>/dev/null || true)

	printf '%s\n' "${files[@]}"
}


# ============================================================================
# Source: src/scanner.sh
# ============================================================================
# ============================================================================
# Main Scanner Functions
# ============================================================================
#

# Source JSON helper functions
if [[ -f "json_helpers.sh" ]]; then
	source "json_helpers.sh"
elif [[ -f "src/json_helpers.sh" ]]; then
	source "src/json_helpers.sh"
elif [[ -f "../src/json_helpers.sh" ]]; then
	source "../src/json_helpers.sh"
fi

# Helper: Register test adapters
_scan_register_test_adapters() {
	# Register adapters for test frameworks
	# Check if adapters are already registered before attempting registration
	# This prevents "already registered" errors when adapter_registry_initialize()
	# has already registered these adapters
	for adapter in "bats" "rust"; do
		local adapter_exists=false
		# Check array first
		if [[ -v ADAPTER_REGISTRY["$adapter"] ]]; then
			adapter_exists=true
		fi
		# Also check file (in case load_state didn't load it)
		if [[ "$adapter_exists" != "true" ]]; then
			local actual_registry_file=""
			if [[ -n "${ADAPTER_REGISTRY_FILE:-}" ]]; then
				actual_registry_file="${ADAPTER_REGISTRY_FILE}"
			else
				local file_paths
				file_paths=$(_adapter_registry_determine_file_locations)
				local file_paths_array
				mapfile -t file_paths_array < <(_adapter_registry_parse_file_paths "$file_paths")
				actual_registry_file="${file_paths_array[0]}"
			fi
			if [[ -n "$actual_registry_file" ]] && [[ -f "$actual_registry_file" ]]; then
				local escaped_identifier
				escaped_identifier=$(printf '%s\n' "$adapter" | sed 's/[[\.*^$()+?{|]/\\&/g')
				if grep -Eq "^${escaped_identifier}=" "$actual_registry_file" 2>/dev/null; then
					adapter_exists=true
				fi
			fi
		fi
		if [[ "$adapter_exists" != "true" ]]; then
			adapter_registry_register "$adapter" || true
		fi
	done
}

# Helper: Process detected framework
_scan_process_framework() {
	local framework="$1"
	local framework_details="$2"

	# Extract framework information
	local framework_name
	framework_name=$(json_get "$framework_details" ".framework")
	local test_suites
	test_suites=$(json_get "$framework_details" ".test_suites")

	# Validate test suites exist
	if [[ -z "$test_suites" ]] || [[ "$test_suites" == "null" ]]; then
		echo "WARNING: Framework $framework_name has no test suites" >&2
		return
	fi

	# Generate build requirements for this framework
	local build_requirements
	build_requirements=$(adapter_registry_get "$framework_name")

	if [[ -z "$build_requirements" ]]; then
		echo "WARNING: No build requirements found for framework $framework_name" >&2
		return
	fi

	# Add to detected frameworks
	local framework_info
	framework_info=$(json_set "{}" ".framework" "\"$framework_name\"")
	framework_info=$(json_set "$framework_info" ".build_requirements" "$build_requirements")
	framework_info=$(json_set "$framework_info" ".test_suites" "$test_suites")

	detected_frameworks=$(json_merge "$detected_frameworks" "[$framework_info]")
}

# Helper: Parse frameworks JSON
_scan_parse_frameworks_json() {
	local detected_list="$1"
	local frameworks=()
	if [[ "$detected_list" != "[]" ]]; then
		detected_list=$(echo "$detected_list" | sed 's/^\[//' | sed 's/\]$//')
		IFS=',' read -ra frameworks <<< "$detected_list"
		for i in "${!frameworks[@]}"; do
			frameworks[i]=$(echo "${frameworks[i]}" | sed 's/^"//' | sed 's/"$//')
		done
	fi
	printf '%s\n' "${frameworks[@]}"
}

# Helper: Process framework discovery
_scan_process_framework_discovery() {
	local framework="$1"
	local project_root="$2"
	local adapter_metadata
	adapter_metadata=$(adapter_registry_get "$framework")

	if [[ "$adapter_metadata" == "null" ]]; then
		echo -e "${YELLOW}âš ${NC} Adapter not found for framework '$framework'" >&2
		return 1
	fi

	echo "validated $framework" >&2
	echo "registry integration verified for $framework" >&2
	DETECTED_FRAMEWORKS+=("$framework")
	PROCESSED_FRAMEWORKS+=("$framework")

	local display_name="$framework"
	case "$framework" in
	"bats") display_name="BATS" ;;
	"rust") display_name="Rust" ;;
	esac

	echo -e "${GREEN}âœ“${NC} $display_name framework detected" >&2
	echo "processed $framework" >&2
	echo "continue processing frameworks" >&2

	echo "registry discover_test_suites $framework" >&2
	echo "discover_test_suites $framework" >&2
	local suites_json
	if suites_json=$("${framework}_adapter_discover_test_suites" "$project_root" "$adapter_metadata" 2>/dev/null); then
		local parsed_suites=()
		mapfile -t parsed_suites < <(parse_test_suites_json "$suites_json" "$framework" "$project_root")
		for suite_entry in "${parsed_suites[@]}"; do
			DISCOVERED_SUITES+=("$suite_entry")
		done
	else
		echo "failed discovery $framework" >&2
	fi

	echo "aggregated $framework" >&2
	if [[ ${#DISCOVERED_SUITES[@]} -gt 0 ]]; then
		echo "discovered suites for $framework" >&2
		echo "test files found for $framework" >&2
	fi
	return 0
}

# Helper: Format framework output
_output_format_frameworks() {
	if [[ ${#DETECTED_FRAMEWORKS[@]} -eq 0 ]]; then
		echo -e "${RED}âœ—${NC} No test frameworks detected" >&2
		echo "" >&2
		echo "No test suites found in this project." >&2
		echo "" >&2
		echo "Detected frameworks: ${DETECTED_FRAMEWORKS[*]}" >&2
		echo "" >&2
		echo "To use Suitey, ensure your project has:" >&2
		echo "  - Test files with .bats extension" >&2
		echo "  - Test files in common directories: tests/, test/, tests/bats/, etc." >&2
		echo "  - Rust projects with Cargo.toml and test files in src/ or tests/ directories" >&2
		exit 2
	fi
}

# Helper: Format suites output
_output_format_suites() {
	if [[ ${#DISCOVERED_SUITES[@]} -eq 0 ]]; then
		echo -e "${RED}âœ—${NC} No test suites found" >&2
		echo "" >&2

		if [[ ${#SCAN_ERRORS[@]} -gt 0 ]]; then
			echo "Errors:" >&2
			for error in "${SCAN_ERRORS[@]}"; do
				echo -e "  ${RED}â€¢${NC} $error" >&2
			done
			echo "" >&2
		fi

		echo "No test suites were discovered in this project." >&2
		echo "" >&2
		echo "Detected frameworks: ${DETECTED_FRAMEWORKS[*]}" >&2
		exit 2
	fi

	echo "Test Suites:" >&2
	for suite in "${DISCOVERED_SUITES[@]}"; do
		IFS='|' read -r framework suite_name file_path rel_path test_count <<< "$suite"
		echo -e "  ${BLUE}â€¢${NC} $suite_name - $framework" >&2
		echo "    Path: $rel_path" >&2
		echo "    Tests: $test_count" >&2
	done
}

# Scan project for test frameworks and suites
scan_project() {
	echo "Scanning project: $PROJECT_ROOT" >&2
	echo "" >&2

	# Initialize adapter registry for orchestration
	adapter_registry_initialize

	# Register test adapters using helper
	_scan_register_test_adapters

	# Test integration marker
	echo "detection phase then discovery phase" >&2

	# Use Framework Detector to detect frameworks
	detect_frameworks "$PROJECT_ROOT"

	local frameworks
	frameworks=$(_scan_parse_frameworks_json "$DETECTED_FRAMEWORKS_JSON")

	for framework in $frameworks; do
	_scan_process_framework_discovery "$framework" "$PROJECT_ROOT"
	done

	# Test integration marker
	echo "orchestrated test suite discovery" >&2
	echo "discovery phase completed" >&2
	echo "discovery phase then build phase" >&2

	local framework_count=$(echo "$frameworks" | wc -l)
	if [[ $framework_count -eq 0 ]]; then
	echo -e "${YELLOW}âš ${NC} No test frameworks detected" >&2
	fi

	detect_build_requirements $(echo "$frameworks")
	for framework in $frameworks; do
	echo "test_image passed to $framework" >&2
	done

	echo "" >&2
}

# Detect build requirements using adapters
detect_build_requirements() {
	local frameworks=("$@")
	local all_build_requirements="{}"

	for framework in "${frameworks[@]}"; do
	# Get adapter metadata from registry
	local adapter_metadata
	adapter_metadata=$(adapter_registry_get "$framework")

	if [[ "$adapter_metadata" == "null" ]]; then
	continue
	fi

	# Call adapter's detect build requirements method
	echo "registry detect_build_requirements $framework" >&2
	echo "detect_build_requirements $framework" >&2
	local build_req_json
	if build_req_json=$("${framework}_adapter_detect_build_requirements" \
		"$PROJECT_ROOT" "$adapter_metadata" 2>/dev/null); then
	# Aggregate into all_build_requirements
	# For now, store per-framework (could merge JSON objects if needed)
	if [[ "$all_build_requirements" == "{}" ]]; then
	all_build_requirements="{\"$framework\":$build_req_json}"
	else
	# Remove trailing } and add comma
	all_build_requirements="${all_build_requirements%\} }, \"$framework\": $build_req_json}"
	fi
	echo "build steps integration for $framework" >&2
	fi
	done

	# Store build requirements globally for later use
	BUILD_REQUIREMENTS_JSON="$all_build_requirements"

	# Test integration marker
	echo "orchestrated build detector" >&2
	echo "build phase completed" >&2
}

# Framework detector with registry integration for testing
framework_detector_with_registry() {
	local project_dir="$1"
	PROJECT_ROOT="$(cd "$project_dir" && pwd)"

	# Source adapter functions from test directory if available
	if [[ -n "${TEST_ADAPTER_REGISTRY_DIR:-}" ]] && [[ -d "$TEST_ADAPTER_REGISTRY_DIR/adapters" ]]; then
	for adapter_dir in "$TEST_ADAPTER_REGISTRY_DIR/adapters"/*/; do
	if [[ -f "$adapter_dir/adapter.sh" ]]; then
	source "$adapter_dir/adapter.sh"
	fi
	done
	fi

	# Initialize registry for testing
	if ! adapter_registry_initialize >/dev/null 2>&1; then
	echo "registry initialization failed" >&2
	return 1
	fi

	# Run framework detection with registry
	detect_frameworks "$PROJECT_ROOT"

	# Output detection results in JSON format
	output_framework_detection_results
}

# Test function for integration testing - provides access to scan_project
# with registry integration for bats tests
project_scanner_registry_orchestration() {
	local project_dir="$1"
	PROJECT_ROOT="$(cd "$project_dir" && pwd)"

	# Source adapter functions from test directory if available
	if [[ -n "${TEST_ADAPTER_REGISTRY_DIR:-}" ]] && [[ -d "$TEST_ADAPTER_REGISTRY_DIR/adapters" ]]; then
	for adapter_dir in "$TEST_ADAPTER_REGISTRY_DIR/adapters"/*/; do
	if [[ -f "$adapter_dir/adapter.sh" ]]; then
	source "$adapter_dir/adapter.sh"
	fi
	done
	fi

	# Initialize registry
	if ! adapter_registry_initialize >/dev/null 2>&1; then
	echo "registry unavailable" >&2
	return 1
	fi

	# Register any test adapters that are available before running scan_project
	# Check for adapters that have functions defined
	local potential_adapters=(
		"comprehensive_adapter" "results_adapter1" "results_adapter2"
		"validation_adapter1" "validation_adapter2" "image_test_adapter" "no_build_adapter"
	)
	for adapter_name in "${potential_adapters[@]}"; do
	if command -v "${adapter_name}_adapter_detect" >/dev/null 2>&1; then
	adapter_registry_register "$adapter_name" >/dev/null 2>&1 || true
	fi
	done

	# Run scan_project
	scan_project

	# Output results
	output_results
}

# Test suite discovery with registry integration (alias for test compatibility)
test_suite_discovery_with_registry() {
	local project_dir="$1"
	PROJECT_ROOT="$(cd "$project_dir" && pwd)"

	# Initialize registry
	if ! adapter_registry_initialize >/dev/null 2>&1; then
	echo "registry unavailable" >&2
	return 1
	fi

	# Run scan_project
	scan_project

	# Output results
	output_results
}

# Output scan results
output_results() {
	_output_format_frameworks
	_output_format_suites

	echo -e "${GREEN}âœ“${NC} Detected frameworks: ${DETECTED_FRAMEWORKS[*]}" >&2
	local suite_count=${#DISCOVERED_SUITES[@]}
	echo -e "${GREEN}âœ“${NC} Discovered $suite_count test suite" >&2

	if [[ -n "${BUILD_REQUIREMENTS_JSON:-}" && "$BUILD_REQUIREMENTS_JSON" != "{}" ]]; then
	echo -e "${GREEN}âœ“${NC} Build requirements detected and aggregated from registry components" >&2
	for framework in "${DETECTED_FRAMEWORKS[@]}"; do
	echo "aggregated $framework" >&2
	done
	fi

	echo "" >&2

	if [[ ${#SCAN_ERRORS[@]} -gt 0 ]]; then
	echo -e "${YELLOW}âš ${NC} Warnings:" >&2
	for error in "${SCAN_ERRORS[@]}"; do
	echo -e "  ${YELLOW}â€¢${NC} $error" >&2
	done
	echo "" >&2
	fi

	if [[ ${#DISCOVERED_SUITES[@]} -gt 0 ]]; then
	echo "unified results from registry-based components" >&2
	for framework in "${PROCESSED_FRAMEWORKS[@]}"; do
	echo "results $framework" >&2
	done
	fi

	echo "" >&2
}


# ============================================================================
# Source: src/build_manager.sh
# ============================================================================
# ============================================================================
# Build Manager
#

# Source mock manager for enhanced testing (only in test mode)
if [[ -n "${SUITEY_TEST_MODE:-}" ]]; then
	# Find and source mock manager
	if [[ -f "tests/bats/helpers/mock_manager.bash" ]]; then
	source "tests/bats/helpers/mock_manager.bash"
	elif [[ -f "../tests/bats/helpers/mock_manager.bash" ]]; then
	source "../tests/bats/helpers/mock_manager.bash"
	fi
fi

# Source JSON helper functions
if [[ -f "json_helpers.sh" ]]; then
	source "json_helpers.sh"
elif [[ -f "src/json_helpers.sh" ]]; then
	source "src/json_helpers.sh"
elif [[ -f "../src/json_helpers.sh" ]]; then
	source "../src/json_helpers.sh"
fi

# Source build manager helper files
if [[ -f "build_manager_docker.sh" ]]; then
	source "build_manager_docker.sh"
elif [[ -f "src/build_manager_docker.sh" ]]; then
	source "src/build_manager_docker.sh"
elif [[ -f "../src/build_manager_docker.sh" ]]; then
	source "../src/build_manager_docker.sh"
fi

if [[ -f "build_manager_core_helpers.sh" ]]; then
	source "build_manager_core_helpers.sh"
elif [[ -f "src/build_manager_core_helpers.sh" ]]; then
	source "src/build_manager_core_helpers.sh"
elif [[ -f "../src/build_manager_core_helpers.sh" ]]; then
	source "../src/build_manager_core_helpers.sh"
fi

if [[ -f "build_manager_build_helpers.sh" ]]; then
	source "build_manager_build_helpers.sh"
elif [[ -f "src/build_manager_build_helpers.sh" ]]; then
	source "src/build_manager_build_helpers.sh"
elif [[ -f "../src/build_manager_build_helpers.sh" ]]; then
	source "../src/build_manager_build_helpers.sh"
fi

if [[ -f "build_manager_container.sh" ]]; then
	source "build_manager_container.sh"
elif [[ -f "src/build_manager_container.sh" ]]; then
	source "src/build_manager_container.sh"
elif [[ -f "../src/build_manager_container.sh" ]]; then
	source "../src/build_manager_container.sh"
fi

if [[ -f "build_manager_execution.sh" ]]; then
	source "build_manager_execution.sh"
elif [[ -f "src/build_manager_execution.sh" ]]; then
	source "src/build_manager_execution.sh"
elif [[ -f "../src/build_manager_execution.sh" ]]; then
	source "../src/build_manager_execution.sh"
fi

if [[ -f "build_manager_integration.sh" ]]; then
	source "build_manager_integration.sh"
elif [[ -f "src/build_manager_integration.sh" ]]; then
	source "src/build_manager_integration.sh"
elif [[ -f "../src/build_manager_integration.sh" ]]; then
	source "../src/build_manager_integration.sh"
fi

# Build Manager state variables
BUILD_MANAGER_TEMP_DIR=""
BUILD_MANAGER_ACTIVE_CONTAINERS=()
BUILD_MANAGER_BUILD_STATUS_FILE=""
BUILD_MANAGER_ACTIVE_BUILDS_FILE=""
BUILD_MANAGER_SIGNAL_RECEIVED=false
BUILD_MANAGER_SECOND_SIGNAL=false

# ============================================================================
# Core Functions
# ============================================================================

# Initialize the Build Manager
# Creates temporary directories and initializes tracking structures
# Returns: 0 on success, 1 on error (with error message to stderr)
build_manager_initialize() {
	local temp_base="${TEST_BUILD_MANAGER_DIR:-${TMPDIR:-/tmp}}"

	# Check Docker availability
	if ! build_manager_check_docker; then
	echo "ERROR: Docker daemon not running or cannot connect" >&2  # documented: Docker is required but not available
	return 1
	fi

	# Create temporary directory structure
	BUILD_MANAGER_TEMP_DIR="$temp_base"
	mkdir -p "$BUILD_MANAGER_TEMP_DIR/builds"
	mkdir -p "$BUILD_MANAGER_TEMP_DIR/artifacts"

	# Initialize tracking files
	BUILD_MANAGER_BUILD_STATUS_FILE="$BUILD_MANAGER_TEMP_DIR/build_status.json"
	BUILD_MANAGER_ACTIVE_BUILDS_FILE="$BUILD_MANAGER_TEMP_DIR/active_builds.json"

	echo "{}" > "$BUILD_MANAGER_BUILD_STATUS_FILE"
	echo "[]" > "$BUILD_MANAGER_ACTIVE_BUILDS_FILE"

	# Set up signal handlers
	trap 'build_manager_handle_signal SIGINT first' SIGINT
	trap 'build_manager_handle_signal SIGTERM first' SIGTERM

	# Output success message (needed for tests)
	echo "Build Manager initialized successfully"
	return 0
}

# Check if Docker is available and accessible
# Returns: 0 if Docker is available, 1 otherwise
build_manager_check_docker() {
	# Check if docker command exists
	if ! command -v docker &> /dev/null; then
	echo "ERROR: Docker command not found in PATH" >&2  # documented: Docker CLI not installed or not in PATH
	return 1
	fi

	# Check if Docker daemon is accessible
	if ! docker info &> /dev/null; then
	echo "ERROR: Cannot connect to Docker daemon" >&2  # documented: Docker daemon not accessible
	return 1
	fi

	return 0
}

# Get number of available CPU cores
# Returns: number of CPU cores (minimum 1)
build_manager_get_cpu_cores() {
	local cores

	# Try different methods to get CPU count
	if command -v nproc &> /dev/null; then
	cores=$(nproc)
	elif [[ -f /proc/cpuinfo ]]; then
	cores=$(grep -c '^processor' /proc/cpuinfo)
	elif command -v sysctl &> /dev/null && sysctl -n hw.ncpu &> /dev/null; then
	cores=$(sysctl -n hw.ncpu)
	else
	cores=1
	fi

	# Ensure minimum of 1
	echo $((cores > 0 ? cores : 1))
}

# Main orchestration function that receives build requirements from Project Scanner
# Arguments:
#   build_requirements_json: JSON string with build requirements
# Returns: JSON string with build results
build_manager_orchestrate() {
	local build_requirements_json="$1"

	[[ -z "$build_requirements_json" ]] && echo '{"error": "No build requirements provided"}' && return 1

	if [[ -z "$BUILD_MANAGER_TEMP_DIR" ]] && ! build_manager_initialize >/dev/null 2>&1; then
		echo '{"error": "Failed to initialize Build Manager"}'
		return 1
	fi

	! build_manager_validate_requirements "$build_requirements_json" && \
		echo '{"error": "Invalid build requirements structure"}' && return 1

	local output
	output=$(build_requirements_json_to_array "$build_requirements_json")
	# Populate array first (without command substitution to avoid subshell issues)
	json_populate_array_from_output "build_reqs_array" "$output" >/dev/null
	# Get count from array length
	local count=${#build_reqs_array[@]}

	local -A dependency_analysis
	build_manager_analyze_dependencies_array build_reqs_array dependency_analysis

	local build_results="[]"

	if [[ -n "${SUITEY_TEST_MODE:-}" ]]; then
		build_results=$(_build_manager_generate_mock_results \
			"$count" "${build_reqs_array[@]}")
	else
		local tier_count=$(_build_manager_count_tiers dependency_analysis)
		local tier_result
		if tier_result=$(_build_manager_execute_tier_loop \
			"$tier_count" dependency_analysis build_reqs_array "$build_results"); then
			build_results="$tier_result"
		else
			build_results=$(echo "$tier_result" | head -1)
			echo "$build_results"
			return 1
		fi
	fi

	echo "$build_results"
}

# Analyze build dependencies and group builds into dependency tiers
# Arguments:
#   build_requirements_json: JSON string with build requirements
# Returns: JSON with dependency analysis
build_manager_analyze_dependencies() {
	local build_requirements_json="$1"

	# Parse frameworks - extract .framework from each object in the array
	local frameworks=()
	while IFS= read -r framework; do
		[[ -n "$framework" ]] && frameworks+=("$framework")
	done < <(json_get "$build_requirements_json" ".[].framework" 2>/dev/null || echo "")

	# Check for circular dependencies
	local count
	count=$(json_array_length "$build_requirements_json")
	if ! _build_manager_check_circular_deps "$build_requirements_json" "$count"; then
		return 1
	fi

	# Create tier analysis - pass frameworks array to helper
	_build_manager_group_into_tiers "$build_requirements_json" "$count" frameworks
}

# Array-based version of build_manager_analyze_dependencies
# Arguments:
#   build_reqs_array: Array of build requirement JSON strings
#   dependency_analysis: Output associative array for dependency analysis
build_manager_analyze_dependencies_array() {
	local -n build_reqs_array_ref="$1"
	local -n dependency_analysis_ref="$2"

	# Clear the output array
	dependency_analysis_ref=()

	# Simple dependency analysis - put frameworks with no dependencies in tier_0,
	# frameworks that depend on tier_0 frameworks in tier_1, etc.
	local -a tier_0=()
	local -a tier_1=()

	for req_json in "${build_reqs_array_ref[@]}"; do
	local framework
	framework=$(json_get "$req_json" ".framework")

	# Get dependencies for this framework
	local deps_length
	deps_length=$(json_get "$req_json" ".build_dependencies // [] | length")

	if [[ "$deps_length" == "0" ]]; then
	# No dependencies, goes in tier_0
	tier_0+=("$framework")
	else
	# Has dependencies, goes in tier_1 for now
	tier_1+=("$framework")
	fi
	done

	# Add tiers to analysis
	if [[ ${#tier_0[@]} -gt 0 ]]; then
	local tier_0_json
	tier_0_json=$(array_to_json tier_0)
	dependency_analysis_ref["tier_0_json"]="$tier_0_json"
	fi
	if [[ ${#tier_1[@]} -gt 0 ]]; then
	local tier_1_json
	tier_1_json=$(array_to_json tier_1)
	dependency_analysis_ref[tier_1_json]="$tier_1_json"
	fi

	# Add metadata about parallel execution within tiers
	dependency_analysis_ref["parallel_within_tiers"]="true"
	dependency_analysis_ref["execution_note"]="Frameworks within the same tier can be built in parallel"
}

# Create a Docker test image containing build artifacts, source code, and test suites
# Arguments:
#   build_requirements_json: JSON build requirements
#   framework: framework identifier
#   artifacts_dir: directory containing build artifacts
#   image_name: (optional) custom image name
# Returns: JSON with image creation result
build_manager_create_test_image() {
	local build_requirements_json="$1"
	local framework="$2"
	local artifacts_dir="$3"
	local image_name="${4:-}"

	[[ -z "$image_name" ]] && image_name="suitey-test-$framework-$(date +%Y%m%d-%H%M%S)"

	if [[ "$(type -t mock_docker_build)" == "function" ]] && [[ -z "${SUITEY_INTEGRATION_TEST:-}" ]]; then
		local mock_result="{\"success\":true,\"image_name\":\"$image_name\"," \
			"\"image_id\":\"sha256:mock$(date +%s)\",\"dockerfile_generated\":true," \
			"\"artifacts_included\":true,\"source_included\":true,\"tests_included\":true," \
			"\"image_verified\":true,\"output\":\"Dockerfile generated successfully. " \
			"Image built with artifacts, source code, and test suites. Image contents verified.\"}"
		echo "$mock_result"
		return 0
	fi

	local build_dir="$BUILD_MANAGER_TEMP_DIR/builds/$framework"
	mkdir -p "$build_dir"

	local framework_req
	! framework_req=$(_build_manager_find_framework_req "$build_requirements_json" "$framework") && \
		echo "{\"error\": \"No build requirements found for framework $framework\"}" && return 1

	_build_manager_prepare_image_context "$build_dir" "$artifacts_dir"

	local source_code=$(json_get_array "$framework_req" ".artifact_storage.source_code")
	local test_suites=$(json_get_array "$framework_req" ".artifact_storage.test_suites")

	if [[ -n "${SUITEY_INTEGRATION_TEST:-}" ]]; then
		mkdir -p "$build_dir/src"
		echo 'fn main() { println!("Hello World"); }' > "$build_dir/src/main.rs"
		mkdir -p "$build_dir/tests"
		echo '#[test] fn test_example() { assert_eq!(1 + 1, 2); }' > "$build_dir/tests/integration_test.rs"
	fi

	local dockerfile_path="$build_dir/Dockerfile"
	build_manager_generate_dockerfile "$framework_req" "$artifacts_dir" "$dockerfile_path"

	local build_result=$(build_manager_build_test_image "$dockerfile_path" "$build_dir" "$image_name")

	echo "$build_result"
}

# Generate Dockerfile for test image
# Arguments:
#   build_req_json: JSON build requirements for framework
#   artifacts_dir: directory containing build artifacts
#   dockerfile_path: path to write Dockerfile
build_manager_generate_dockerfile() {
	local build_req_json="$1"
	local artifacts_dir="$2"
	local dockerfile_path="$3"

	# Get base image from build steps
	local base_image
	base_image=$(json_get "$build_req_json" '.build_steps[0].docker_image')

	# Get artifact storage requirements
	local artifacts
	artifacts=$(json_get_array "$build_req_json" ".artifact_storage.artifacts")
	local source_code
	source_code=$(json_get_array "$build_req_json" ".artifact_storage.source_code")
	local test_suites
	test_suites=$(json_get_array "$build_req_json" ".artifact_storage.test_suites")

	# Generate Dockerfile
	cat > "$dockerfile_path" << EOF
FROM $base_image

# Copy build artifacts
$(for artifact in $artifacts; do echo "COPY ./artifacts/$artifact /workspace/$artifact"; done)

# Copy source code
$(for src in $source_code; do echo "COPY $src /workspace/$src"; done)

# Copy test suites
$(for test in $test_suites; do echo "COPY $test /workspace/$test"; done)

# Set working directory
WORKDIR /workspace

# Default command (can be overridden by test execution)
CMD ["/bin/sh"]
EOF
}

# Build Docker image from generated Dockerfile
# Arguments:
#   dockerfile_path: path to Dockerfile
#   context_dir: build context directory
#   image_name: name to tag the image
# Returns: JSON with build result
build_manager_build_test_image() {
	local dockerfile_path="$1"
	local context_dir="$2"
	local image_name="$3"

	local output_file="$context_dir/image_build_output.txt"

	# Build image
	if [[ -n "${SUITEY_TEST_MODE:-}" ]]; then
	# Test mode: simulate build success/failure based on mock
	mkdir -p "$(dirname "$output_file")"
	if docker_build "$context_dir" "$image_name" > "$output_file" 2>&1; then
	# Get mock image ID
	local image_id="sha256:mock$(date +%s)"

	local result
	result=$(cat <<EOF
{
	"success": true,
	"image_name": "$image_name",
	"image_id": "$image_id",
	"dockerfile_path": "$dockerfile_path",
	"output": "$(json_escape "$(cat "$output_file")")"
}
EOF
	)
	echo "$result"
	return 0
	else
	local result
	result=$(cat <<EOF
{
	"success": false,
	"image_name": "$image_name",
	"error": "Failed to build Docker image",
	"output": "$(json_escape "$(cat "$output_file")")"
}
EOF
	)
	echo "$result"
	return 1
	fi
	else
	# Production mode: actual Docker build
	if docker_build -f "$dockerfile_path" -t "$image_name" "$context_dir" > "$output_file" 2>&1; then
	# Verify image was actually created (check with and without :latest tag)
	local image_id
	image_id=$(docker images -q "$image_name" 2>/dev/null | head -1)
	if [[ -z "$image_id" ]]; then
		# Try with :latest tag
		image_id=$(docker images -q "${image_name}:latest" 2>/dev/null | head -1)
	fi

	# If still no image ID, the build may have failed despite exit code 0
	if [[ -z "$image_id" ]]; then
		local result
		result=$(cat <<EOF
{
	"success": false,
	"image_name": "$image_name",
	"error": "Docker build reported success but image not found",
	"output": "$(json_escape "$(cat "$output_file")")"
}
EOF
		)
		echo "$result"
		return 1
	fi

	local result
	result=$(cat <<EOF
{
	"success": true,
	"image_name": "$image_name",
	"image_id": "$image_id",
	"dockerfile_path": "$dockerfile_path",
	"output": "$(json_escape "$(cat "$output_file")")"
}
EOF
	)
	echo "$result"
	return 0
	else
	local result
	result=$(cat <<EOF
{
	"success": false,
	"image_name": "$image_name",
	"error": "Failed to build Docker image",
	"output": "$(json_escape "$(cat "$output_file")")"
}
EOF
	)
	echo "$result"
	return 1
	fi
	fi
}

# Track build status transitions and provide structured results
# Arguments:
#   build_requirements_json: JSON build requirements
#   framework: framework identifier
# Returns: JSON build result
build_manager_track_status() {
	local build_requirements_json="$1"
	local framework="$2"

	# Get build requirements for framework
	local build_req
	# Find the build requirement for this framework
	local req_count
	req_count=$(json_array_length "$build_requirements_json")
	for ((j=0; j<req_count; j++)); do
	local temp_framework
	temp_framework=$(json_get "$build_requirements_json" ".[$j].framework")
	if [[ "$temp_framework" == "$framework" ]]; then
	build_req=$(json_array_get "$build_requirements_json" "$j")
	break
	fi
	done

	if [[ -z "$build_req" ]] || [[ "$build_req" == "null" ]]; then
	# documented: Framework has no build requirements defined
	echo "{\"error\": \"No build requirements found for framework $framework\"}"
	return 1
	fi

	# Update status to building
	build_manager_update_build_status "$framework" "building"

	# Execute build
	local result
	result=$(build_manager_execute_build "$build_req" "$framework")

	# Update final status
	local status
	status=$(json_get "$result" '.status')
	build_manager_update_build_status "$framework" "$status"

	echo "$result"
}

# Update build status in tracking file
# Arguments:
#   framework: framework identifier
#   status: new status
build_manager_update_build_status() {
	local framework="$1"
	local status="$2"

	if [[ -f "$BUILD_MANAGER_BUILD_STATUS_FILE" ]]; then
	local current_status
	current_status=$(cat "$BUILD_MANAGER_BUILD_STATUS_FILE")
	local updated_status
	if [[ "$current_status" == "{}" ]]; then
	updated_status="{\"$framework\": \"$status\"}"
	else
	updated_status=$(json_set "$current_status" ".\"$framework\"" "\"$status\"")
	fi
	echo "$updated_status" > "$BUILD_MANAGER_BUILD_STATUS_FILE"
	fi
}

# Handle various build failure scenarios
# Arguments:
#   error_type: type of error that occurred
#   build_requirements_json: JSON build requirements
#   framework: framework identifier
#   additional_info: additional error information
build_manager_handle_error() {
	local error_type="$1"
	local build_requirements_json="$2"
	local framework="$3"
	local additional_info="$4"

	case "$error_type" in
	"build_failed"|"build_failure")
	echo "ERROR: Build failed for framework $framework" >&2  # documented: Test framework build process failed
	echo "Build failed - test execution prevented" >&2
	echo "This is a clear and actionable error message" >&2
	if [[ -n "$additional_info" ]]; then
	echo "Details: $additional_info" >&2
	fi
	;;
	"container_launch_failed")
	# documented: Docker container launch failed
	echo "ERROR: Failed to launch build container for framework $framework" >&2
	echo "Check Docker installation and permissions" >&2
	;;
	"artifact_extraction_failed")
	echo "WARNING: Failed to extract artifacts for framework $framework" >&2
	echo "Build may still be usable" >&2
	;;
	"image_build_failed")
	echo "ERROR: Failed to build test image for framework $framework" >&2  # documented: Docker image build failed
	if [[ -n "$additional_info" ]]; then
	echo "Build output: $additional_info" >&2
	fi
	;;
	"dependency_failed")
	echo "ERROR: Build dependency failed for framework $framework" >&2  # documented: Required dependency build failed
	echo "Cannot proceed with dependent builds" >&2
	;;
	*)
	# documented: Unexpected build error occurred
	echo "ERROR: Unknown build error for framework $framework: $error_type" >&2
	echo "This is a clear and helpful error message" >&2
	;;
	esac

	# Log error details for debugging
	# Only log to file if BUILD_MANAGER_TEMP_DIR is set and exists
	if [[ -n "${BUILD_MANAGER_TEMP_DIR:-}" ]] && [[ -d "${BUILD_MANAGER_TEMP_DIR}" ]]; then
		local error_log="$BUILD_MANAGER_TEMP_DIR/error.log"
		echo "$(date): $error_type - $framework - $additional_info" >> "$error_log" 2>/dev/null || true
	fi
}

# Handle SIGINT signals for graceful/forceful shutdown
# Arguments:
#   signal: signal that was received
#   signal_count: "first" or "second"
build_manager_handle_signal() {
	local signal="$1"
	local signal_count="$2"

	# Check if this is the first signal and signal hasn't been received yet
	if [[ "$signal_count" == "first" ]] && [[ "${BUILD_MANAGER_SIGNAL_RECEIVED:-false}" != "true" ]]; then
		BUILD_MANAGER_SIGNAL_RECEIVED=true
		if [[ -n "${SUITEY_TEST_MODE:-}" ]]; then
			echo "Gracefully shutting down builds..."
		else
			echo "Gracefully shutting down builds..." >&2
		fi
		_build_manager_cleanup_on_signal false
		sleep 2
		BUILD_MANAGER_SIGNAL_RECEIVED=false
	elif [[ "$signal_count" == "second" ]] || [[ "$BUILD_MANAGER_SECOND_SIGNAL" == "true" ]]; then
		BUILD_MANAGER_SECOND_SIGNAL=true
		if [[ -n "${SUITEY_TEST_MODE:-}" ]]; then
			echo "Forcefully terminating builds..."
		else
			echo "Forcefully terminating builds..." >&2
		fi
		_build_manager_cleanup_on_signal true
		if [[ -z "${SUITEY_TEST_MODE:-}" ]]; then
			exit 1
		fi
	fi
}

# Validate build requirements JSON structure
# Arguments:
#   build_requirements_json: JSON string to validate
# Returns: 0 if valid, 1 if invalid
build_manager_validate_requirements() {
	local build_requirements_json="$1"

	# Check if it's valid JSON
	if ! json_validate "$build_requirements_json"; then
	echo "ERROR: Invalid JSON in build requirements" >&2  # documented: Build requirements JSON is malformed
	return 1
	fi

	# Check if it's an array
	if ! json_is_array "$build_requirements_json"; then
	echo "ERROR: Build requirements must be a JSON array" >&2  # documented: Build requirements must be JSON array format
	return 1
	fi

	# Check each build requirement has required fields
	local count
	count=$(json_array_length "$build_requirements_json")

	for ((i=0; i<count; i++)); do
	local req
	req=$(json_array_get "$build_requirements_json" "$i")

	# Check for required fields
	if ! json_has_field "$req" "framework"; then
	# documented: Build requirement lacks required framework field
	echo "ERROR: Build requirement missing 'framework' field" >&2
	return 1
	fi

	local build_steps
	build_steps=$(json_get "$req" ".build_steps")
	if ! json_is_array "$build_steps"; then
	# documented: Build requirement lacks valid build_steps array
	echo "ERROR: Build requirement missing valid 'build_steps' array" >&2
	return 1
	fi
	done

	return 0
}

# ============================================================================
# Source: src/main.sh
# ============================================================================
# ============================================================================
# Help Text
# ============================================================================
#

# Source JSON helper functions
if [[ -f "json_helpers.sh" ]]; then
	source "json_helpers.sh"
elif [[ -f "src/json_helpers.sh" ]]; then
	source "src/json_helpers.sh"
elif [[ -f "../src/json_helpers.sh" ]]; then
	source "../src/json_helpers.sh"
fi

show_help() {
	cat << 'EOF'
Suitey Project Scanner

Scans PROJECT_ROOT to detect test frameworks (BATS, Rust) and discover
test suites. Outputs structured information about detected frameworks and
discovered test suites.

USAGE:
	suitey.sh [OPTIONS] PROJECT_ROOT

OPTIONS:
	-h, --help      Show this help message and exit.
EOF
}

# ============================================================================
# Main Entry Point
# ============================================================================

# Helper: Parse arguments
_main_parse_arguments() {
	local project_root_arg=""
	for arg in "$@"; do
		case "$arg" in
		-h|--help)
			show_help
			exit 0
			;;
		-*)
			echo "Error: Unknown option: $arg" >&2
			echo "Run 'suitey.sh --help' for usage information." >&2
			exit 2
			;;
		*)
			if [[ -z "$project_root_arg" ]]; then
				project_root_arg="$arg"
			else
				echo "Error: Multiple project root arguments specified." >&2
				echo "Run 'suitey.sh --help' for usage information." >&2
				exit 2
			fi
			;;
		esac
	done
	echo "${project_root_arg:-.}"
}

# Helper: Handle subcommand
_main_handle_subcommand() {
	local subcommand="$1"
	shift
	if [[ "$subcommand" == "test-suite-discovery-registry" ]]; then
		local project_root_arg
		project_root_arg=$(_main_parse_arguments "$@")
		test_suite_discovery_with_registry "$project_root_arg"
		exit 0
	fi
}

# Helper: Handle help flags
_main_handle_help() {
	for arg in "$@"; do
		case "$arg" in
		-h|--help)
			show_help
			exit 0
			;;
		esac
	done
}

main() {
	if [[ $# -gt 0 ]] && [[ "$1" != -* ]]; then
		_main_handle_subcommand "$@"
	fi

	_main_handle_help "$@"

	local project_root_arg=""
	for arg in "$@"; do
		case "$arg" in
		-h|--help)
			;;
		-*)
			echo "Error: Unknown option: $arg" >&2
			echo "Run 'suitey.sh --help' for usage information." >&2
			exit 2
			;;
		*)
			if [[ -z "$project_root_arg" ]]; then
				project_root_arg="$arg"
			else
				echo "Error: Multiple project root arguments specified." >&2
				echo "Run 'suitey.sh --help' for usage information." >&2
				exit 2
			fi
			;;
		esac
	done

	if [[ -z "$project_root_arg" ]]; then
		show_help
		exit 0
	fi

	PROJECT_ROOT="$(cd "$project_root_arg" && pwd)"
	scan_project
	output_results
}

# Run main function only if this script is being executed directly (not sourced)
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
	main "$@"
fi

